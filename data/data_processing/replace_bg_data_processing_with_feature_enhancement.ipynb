{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **REPLACE-BG DATA PROCESSING**   \n",
    "- **With feature enhancement**  \n",
    "  - 5 minute change\n",
    "  - 30 minute change\n",
    "  - 60 minute change\n",
    "  - 60 minute moving average\n",
    "  - 60 minute standard deviation\n",
    "  - 60 minute largest increase\n",
    "  - 60 minute largest decrease\n",
    "  - 360 minute moving average\n",
    "  - 360 minute standard deviation\n",
    "  \n",
    "- **2:1:2 hypo:eu:hyper sampling ratio**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CONTENTS**\n",
    "\n",
    "[1. Requirements & Environment](#1-requirements--environment)  \n",
    "[2. Read in Replace-BG Dataset](#2-read-in-replace-bg-dataset)  \n",
    "[3. Initial Processing & Train/Validation/Test Split](#3-initial-processing--trainvalidationtest-split)  \n",
    "[4. Training Data Processing](#4-training-data-processing)  \n",
    "[5. Validation Data Processing](#5-validation-data-processing)  \n",
    "[6. Test Data Processing](#6-test-data-processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Requirements & Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_processing_modules import *\n",
    "from data_processing_parameters import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Read in Replace-BG Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Using a relative path from current working directory\n",
    "replace_bg_path = os.path.join('..', 'source_data', 'SourceData', 'ReplaceBG', 'Data_tables', 'hdevicecgm.txt')\n",
    "\n",
    "# Read the data\n",
    "replace_cgm_data = pd.read_csv(replace_bg_path, delimiter='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.    ReplaceBG Initial Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes calibration data / direct blood glucose measurements from dataset leaving only CGM data\n",
    "replace_cgm_data = replace_cgm_data[replace_cgm_data['RecordType'] == 'CGM']\n",
    "\n",
    "# Drop columns that will not be required\n",
    "replace_cgm_data = replace_cgm_data.drop(columns=['RecID', 'ParentHDeviceUploadsID', 'SiteID', 'DexInternalDtTmDaysFromEnroll', 'DexInternalTm', 'RecordType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by ptid, then devicedttmdaysfromenroll then devicetm to separate the data into individual patient time series sequences\n",
    "replace_cgm_data = replace_cgm_data.sort_values(by=['PtID', 'DeviceDtTmDaysFromEnroll', 'DeviceTm']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the DeviceDtTmDaysFromEnroll to the base date\n",
    "# base date imported from data_processing_parameters.py\n",
    "replace_cgm_data['DateTime'] = base_date + pd.to_timedelta(replace_cgm_data['DeviceDtTmDaysFromEnroll'], unit='D')\n",
    "\n",
    "# add device time to the date time to get a full datetime stamp\n",
    "replace_cgm_data['DateTime'] = replace_cgm_data['DateTime'] + pd.to_timedelta(replace_cgm_data['DeviceTm'])\n",
    "\n",
    "# Drop DeviceDtTmDaysFromEnroll column as no longer needed\n",
    "replace_cgm_data = replace_cgm_data.drop(columns=['DeviceDtTmDaysFromEnroll'])\n",
    "\n",
    "# Ensure Data is still sorted by Patient ID and DateTime\n",
    "replace_cgm_data = replace_cgm_data.sort_values(by=['PtID', 'DateTime'], ascending= [True, True])\n",
    "\n",
    "# Drop DeviceTm column as no longer needed\n",
    "replace_cgm_data = replace_cgm_data.drop(columns=['DeviceTm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate replace_cgm into individual patient time series dfs\n",
    "replace_cgm_data_dict = separate_ptid_data(replace_cgm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardises the earliest date for each patient\n",
    "replace_cgm_data_dict = align_start_date(replace_cgm_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation and test datasets for each patient maintaining the time series order\n",
    "replace_cgm_training_data = {}\n",
    "replace_cgm_validation_data = {}\n",
    "replace_cgm_test_data = {}\n",
    "\n",
    "for ptid, df in replace_cgm_data_dict.items():\n",
    "    train, test = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "    train, val = train_test_split(train, test_size=0.1, shuffle=False)\n",
    "    replace_cgm_training_data[ptid] = train\n",
    "    replace_cgm_validation_data[ptid] = val\n",
    "    replace_cgm_test_data[ptid] = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.    ReplaceBG Training Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data points for single missing values\n",
    "# add engineered features\n",
    "for ptid, df in replace_cgm_training_data.items():\n",
    "    df = df.copy()\n",
    "    df['real_value_flag'] = 1\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "\n",
    "    # Identify rows where TimeDiff is around 600 seconds (10 min)\n",
    "    mask = (df['TimeDiff'] > 595) & (df['TimeDiff'] < 605)\n",
    "    insert_rows = df[mask].copy()\n",
    "\n",
    "    if not insert_rows.empty:\n",
    "        # Modify new rows: set `real_value_flag = 0`, shift `DateTime`, and set `GlucoseValue = NaN`\n",
    "        insert_rows['real_value_flag'] = 0\n",
    "        insert_rows['DateTime'] -= pd.to_timedelta(5, unit='m')\n",
    "        insert_rows['GlucoseValue'] = np.nan\n",
    "\n",
    "        # Append new rows to the dataframe and sort\n",
    "    df = pd.concat([df, insert_rows]).sort_values(by='DateTime').reset_index(drop=True)\n",
    "\n",
    "    # Linearly interpolate the glucose value\n",
    "    df['GlucoseValue'] = df['GlucoseValue'].interpolate(method='linear')\n",
    "\n",
    "    # Add engineered features        \n",
    "    df['5min_change'] = df['GlucoseValue'].diff(1)\n",
    "    df['30min_change'] = df['GlucoseValue'].diff(6)\n",
    "    df['1hr_change'] = df['GlucoseValue'].diff(12)\n",
    "\n",
    "    df['1hr_mov_avg'] = df['GlucoseValue'].rolling(window=12).mean()\n",
    "    df['1hr_mov_std'] = df['GlucoseValue'].rolling(window=12).std()\n",
    "\n",
    "    df['1hr_largest_increase'] = df['5min_change'].rolling(window=12).max()\n",
    "    df['1hr_largest_decrease'] = df['5min_change'].rolling(window=12).min()\n",
    "\n",
    "    df['6hr_mov_avg'] = df['GlucoseValue'].rolling(window=72).mean()\n",
    "    df['6hr_mov_std'] = df['GlucoseValue'].rolling(window=72).std()\n",
    "\n",
    "    # create hour and minute columns~\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    # creates a rolling sum to determins complete data sequences suitable for use\n",
    "    # data sequences that hold missing data over  gaps greater that 10 minutes 5 seconds will be excluded\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "    df['TimeDiffFlag'] = df['TimeDiff'].apply(lambda x: 0 if x < 295 or x > 305 else 1)\n",
    "    df['RollingTimeDiffFlag'] = df['TimeDiffFlag'].rolling(window=96).sum()\n",
    "\n",
    "    # drop columns\n",
    "    df = df.drop(columns=['DateTime', 'TimeDiff', 'TimeDiffFlag', 'real_value_flag'])\n",
    "\n",
    "    #drop first 288 rows due to nan values\n",
    "    df = df[288:]\n",
    "\n",
    "    # replace the initial df with the new df\n",
    "    replace_cgm_training_data[ptid] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create slices of total input length\n",
    "\n",
    "replace_training_slices = []\n",
    "\n",
    "for ptid, df in replace_cgm_training_data.items():\n",
    "    rolling_flag_array = df[\"RollingTimeDiffFlag\"].to_numpy()  # Convert to NumPy array for fast indexing\n",
    "    num_rows = len(df)\n",
    "    starting_index = 0\n",
    "\n",
    "    while starting_index + slice_size <= num_rows:\n",
    "        if rolling_flag_array[starting_index + slice_size - 1] == 96:  # Use precomputed array\n",
    "            replace_training_slices.append(df.iloc[starting_index:starting_index + slice_size])\n",
    "            starting_index += 4  # Move by overlap\n",
    "        else:\n",
    "            starting_index += 1  # Ensure progress to avoid infinite loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142749, 1235425, 970502)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split slices into hypo, eu and hyper slices\n",
    "\n",
    "hypo_training_slices = []\n",
    "eu_training_slices = []\n",
    "hyper_training_slices = []\n",
    "\n",
    "for slice in replace_training_slices:\n",
    "\n",
    "    target_glucose_values = slice.iloc[-target_size:]['GlucoseValue'].values\n",
    "\n",
    "    hypo_value_count = np.sum(target_glucose_values < 70)\n",
    "    eu_value_count = np.sum((target_glucose_values >= 70) & (target_glucose_values <= 180))\n",
    "    hyper_value_count = np.sum(target_glucose_values > 180)\n",
    "\n",
    "    # minimum points required for a slice to be classed as hypo or hyper\n",
    "    min_points = 6\n",
    "\n",
    "    if hypo_value_count >= min_points:\n",
    "        hypo_training_slices.append(slice)\n",
    "    elif hyper_value_count >= min_points:\n",
    "        hyper_training_slices.append(slice)\n",
    "    else:\n",
    "        eu_training_slices.append(slice)\n",
    "\n",
    "\n",
    "len(hypo_training_slices), len(eu_training_slices), len(hyper_training_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21217, 21886, 22365, 43952)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# profile hypo slices by where the hypo occurs in the slice to ensure even distribution\n",
    "\n",
    "_030_slices = []\n",
    "_3060_slices = []\n",
    "_6090_slices = []\n",
    "_90120_slices = []\n",
    "\n",
    "for slice in hypo_training_slices:\n",
    "\n",
    "    _030_values = slice.iloc[-24:-18]['GlucoseValue'].values\n",
    "    _3060_values = slice.iloc[-18:-12]['GlucoseValue'].values\n",
    "    _6090_values = slice.iloc[-12:-6]['GlucoseValue'].values\n",
    "    _90120_values = slice.iloc[-6:]['GlucoseValue'].values\n",
    "\n",
    "    _030_count = np.sum(_030_values < 70)\n",
    "    _3060_count = np.sum(_3060_values < 70)\n",
    "    _6090_count = np.sum(_6090_values < 70)\n",
    "    _90120_count = np.sum(_90120_values < 70)\n",
    "\n",
    "    min_points = 6\n",
    "\n",
    "    if _90120_count >= min_points:\n",
    "        _90120_slices.append(slice)\n",
    "    elif _6090_count >= min_points:\n",
    "        _6090_slices.append(slice)\n",
    "    elif _3060_count >= min_points:\n",
    "        _3060_slices.append(slice)\n",
    "    elif _030_count >= min_points:\n",
    "        _030_slices.append(slice)\n",
    "\n",
    "len(_030_slices), len(_3060_slices),len(_6090_slices), len(_90120_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109420"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiled_hypo_slices = _030_slices + _3060_slices + _6090_slices + _90120_slices\n",
    "\n",
    "len(profiled_hypo_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_training_dict = {idx: slice for idx, slice in enumerate(eu_training_slices)}\n",
    "hyper_training_dict = {idx: slice for idx, slice in enumerate(hyper_training_slices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = int(len(profiled_hypo_slices)/2)\n",
    "eu_training_dict = undersample_dict(eu_training_dict, target_size)\n",
    "eu_training_list = list(eu_training_dict.values())\n",
    "\n",
    "target_size = len(profiled_hypo_slices)\n",
    "\n",
    "hyper_training_dict = undersample_dict(hyper_training_dict, target_size)\n",
    "hyper_training_list = list(hyper_training_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54710, 109420)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eu_training_list), len(hyper_training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_slice_list = profiled_hypo_slices + eu_training_list + hyper_training_list\n",
    "\n",
    "random.shuffle(training_slice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Merge all the slices into a single DataFrame to calculate normalisation parameters\"\"\"\n",
    "training_df = pd.concat(training_slice_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 153.1055921182904, Std: 70.26895577737373\n",
      "\n",
      "GlucoseValue: Mean = 153.1055921182904, Std = 70.26895577737373\n",
      "5min_change: Mean = -0.14247241135075855, Std = 5.8905233586269405\n",
      "30min_change: Mean = -0.9545850469140316, Std = 26.265753922172937\n",
      "1hr_change: Mean = -2.0924585884664597, Std = 43.76626352575408\n",
      "1hr_mov_avg: Min = 39.0, Max = 401.0\n",
      "6hr_mov_avg: Min = 39.0, Max = 401.0\n",
      "1hr_mov_std: Min = 0.0, Max = 167.46946804499115\n",
      "6hr_mov_std: Min = 0.0, Max = 169.20324889498823\n",
      "1hr_largest_increase: Min = -18.0, Max = 318.0\n",
      "1hr_largest_decrease: Min = -355.0, Max = 19.0\n"
     ]
    }
   ],
   "source": [
    "z_score_list = [\"GlucoseValue\", \"5min_change\", \"30min_change\", \"1hr_change\"]\n",
    "\n",
    "min_max_list = [\n",
    "    \n",
    "    \"1hr_mov_avg\", \"6hr_mov_avg\",\n",
    "    \"1hr_mov_std\", \"6hr_mov_std\",\n",
    "    \"1hr_largest_increase\", \"1hr_largest_decrease\"\n",
    "]\n",
    "\n",
    "# Check the mean and standard deviation\n",
    "training_mean = training_df['GlucoseValue'].mean()\n",
    "training_std = training_df['GlucoseValue'].std()\n",
    "print(f\"Mean: {training_mean}, Std: {training_std}\\n\")\n",
    "\n",
    "mean_std_dict = {}\n",
    "min_max_dict = {}\n",
    "\n",
    "for col in z_score_list:\n",
    "    mean_std_dict[col] = (training_df[col].mean(), training_df[col].std())\n",
    "\n",
    "for col in z_score_list:\n",
    "    print(f\"{col}: Mean = {mean_std_dict[col][0]}, Std = {mean_std_dict[col][1]}\")\n",
    "\n",
    "for col in min_max_list:\n",
    "    min_max_dict[col] = (training_df[col].min(), training_df[col].max())\n",
    "\n",
    "for col in min_max_list:\n",
    "    print(f\"{col}: Min = {min_max_dict[col][0]}, Max = {min_max_dict[col][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_training_slices = []\n",
    "\n",
    "z_score_features = [\"GlucoseValue\", \"5min_change\", \"30min_change\", \"1hr_change\"]\n",
    "\n",
    "min_max_features = [\n",
    "    \"1hr_mov_avg\", \"6hr_mov_avg\",\n",
    "    \"1hr_mov_std\", \"6hr_mov_std\",\n",
    "    \"1hr_largest_increase\", \"1hr_largest_decrease\"\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(training_df[min_max_features])\n",
    "# Normalize using z-score normalization for all columns in col_list\n",
    "\n",
    "for slice in training_slice_list:\n",
    "    slice = slice.copy()\n",
    "    for col in z_score_features:\n",
    "        slice.loc[:, col] = (slice[col] - mean_std_dict[col][0]) / mean_std_dict[col][1]\n",
    "\n",
    "    for col in min_max_features:\n",
    "        slice.loc[:, col] = (slice[col] - min_max_dict[col][0]) / (min_max_dict[col][1] - min_max_dict[col][0])\n",
    "\n",
    "    slice.drop(columns=['RollingTimeDiffFlag', 'PtID'], inplace=True)\n",
    "\n",
    "    normalised_training_slices.append(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlucoseValue</th>\n",
       "      <th>5min_change</th>\n",
       "      <th>30min_change</th>\n",
       "      <th>1hr_change</th>\n",
       "      <th>1hr_mov_avg</th>\n",
       "      <th>1hr_mov_std</th>\n",
       "      <th>1hr_largest_increase</th>\n",
       "      <th>1hr_largest_decrease</th>\n",
       "      <th>6hr_mov_avg</th>\n",
       "      <th>6hr_mov_std</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48456</th>\n",
       "      <td>-1.623841</td>\n",
       "      <td>0.024187</td>\n",
       "      <td>0.036343</td>\n",
       "      <td>-0.020736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.217657</td>\n",
       "      <td>0.491588</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48457</th>\n",
       "      <td>-1.481530</td>\n",
       "      <td>1.721829</td>\n",
       "      <td>0.417067</td>\n",
       "      <td>0.276296</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.208180</td>\n",
       "      <td>0.477437</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48458</th>\n",
       "      <td>-1.353451</td>\n",
       "      <td>1.552065</td>\n",
       "      <td>0.759719</td>\n",
       "      <td>0.481934</td>\n",
       "      <td>0.006676</td>\n",
       "      <td>0.035597</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.199317</td>\n",
       "      <td>0.462753</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48459</th>\n",
       "      <td>-1.396144</td>\n",
       "      <td>-0.485106</td>\n",
       "      <td>0.645502</td>\n",
       "      <td>0.413388</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.042156</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.449248</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48460</th>\n",
       "      <td>-1.353451</td>\n",
       "      <td>0.533479</td>\n",
       "      <td>0.759719</td>\n",
       "      <td>0.481934</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>0.048866</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.182436</td>\n",
       "      <td>0.434579</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
       "48456     -1.623841     0.024187      0.036343   -0.020736     0.000000   \n",
       "48457     -1.481530     1.721829      0.417067    0.276296     0.002302   \n",
       "48458     -1.353451     1.552065      0.759719    0.481934     0.006676   \n",
       "48459     -1.396144    -0.485106      0.645502    0.413388     0.010359   \n",
       "48460     -1.353451     0.533479      0.759719    0.481934     0.014733   \n",
       "\n",
       "       1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
       "48456     0.000000              0.053571              0.941176     0.217657   \n",
       "48457     0.017237              0.083333              0.949198     0.208180   \n",
       "48458     0.035597              0.083333              0.949198     0.199317   \n",
       "48459     0.042156              0.083333              0.941176     0.190800   \n",
       "48460     0.048866              0.083333              0.941176     0.182436   \n",
       "\n",
       "       6hr_mov_std  Hour  Minute  \n",
       "48456     0.491588     4      32  \n",
       "48457     0.477437     4      37  \n",
       "48458     0.462753     4      42  \n",
       "48459     0.449248     4      47  \n",
       "48460     0.434579     4      52  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_training_slices[0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/training/encoder_slices'\n",
    "decoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/training/decoder_slices'\n",
    "target_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/training/target_slices'\n",
    "\n",
    "os.makedirs(encoder_dir, exist_ok=True)\n",
    "os.makedirs(decoder_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Define columns to zero out in decoder input\n",
    "zero_out_columns = [\n",
    "    'GlucoseValue', '5min_change', '30min_change', '1hr_change', \n",
    "    '1hr_mov_avg', '1hr_mov_std', '1hr_largest_increase', \n",
    "    '1hr_largest_decrease', '6hr_mov_avg', '6hr_mov_std'\n",
    "]\n",
    "\n",
    "# Process slices efficiently\n",
    "for count, slice in enumerate(normalised_training_slices):\n",
    "\n",
    "    # Define Encoder, Decoder, and Target sequences (Avoid Copying)\n",
    "    encoder_input = slice.iloc[:encoder_input_size]\n",
    "    target = slice.iloc[encoder_input_size: ]['GlucoseValue']\n",
    "\n",
    "    # Modify Decoder Input In-Place (Vectorized)\n",
    "    decoder_input = slice.iloc[-decoder_input_size:].copy().reset_index(drop=True)\n",
    "    decoder_input.iloc[start_token_size:, decoder_input.columns.get_indexer(zero_out_columns)] = 0 \n",
    "    decoder_input = decoder_input.values  # Convert to NumPy array\n",
    "\n",
    "    # Define file paths\n",
    "    encoder_path = os.path.join(encoder_dir, f\"{count}.pt\")\n",
    "    decoder_path = os.path.join(decoder_dir, f\"{count}.pt\")\n",
    "    target_path = os.path.join(target_dir, f\"{count}.pt\")\n",
    "\n",
    "    # Save tensors without unnecessary copies\n",
    "    torch.save(torch.tensor(encoder_input.values, dtype=torch.float32), encoder_path)\n",
    "    torch.save(torch.tensor(decoder_input, dtype=torch.float32), decoder_path)\n",
    "    torch.save(torch.tensor(target.values, dtype=torch.float32), target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Encoder Shape: (72, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "67     -0.015734     0.024187     -0.839322   -1.026077     0.369475   \n",
      "68     -0.072658    -0.654870     -0.877394   -1.026077     0.358656   \n",
      "69     -0.172275    -1.164163     -0.953539   -1.117471     0.346915   \n",
      "70     -0.286123    -1.333927     -1.105828   -1.163169     0.334715   \n",
      "71     -0.343048    -0.654870     -0.991611   -1.186017     0.322284   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "67     0.089555              0.053571              0.930481     0.367442   \n",
      "68     0.088342              0.053571              0.930481     0.365869   \n",
      "69     0.088731              0.053571              0.930481     0.364104   \n",
      "70     0.094133              0.053571              0.927808     0.362147   \n",
      "71     0.097632              0.053571              0.927808     0.360114   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "67     0.109447  16.0    21.0  \n",
      "68     0.110040  16.0    26.0  \n",
      "69     0.111496  16.0    31.0  \n",
      "70     0.114154  16.0    36.0  \n",
      "71     0.117359  16.0    41.0  \n",
      "\n",
      " Decoder Shape: (36, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "6      -0.015734    -0.654870     -1.029684   -1.048925     0.380295   \n",
      "7      -0.015734     0.024187     -0.839322   -1.026077     0.369475   \n",
      "8      -0.072658    -0.654870     -0.877394   -1.026077     0.358656   \n",
      "9      -0.172275    -1.164163     -0.953539   -1.117471     0.346915   \n",
      "10     -0.286123    -1.333927     -1.105828   -1.163169     0.334715   \n",
      "11     -0.343048    -0.654870     -0.991611   -1.186017     0.322284   \n",
      "12      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "13      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "14      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "15      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "16      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "17      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "18      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "19      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "20      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "21      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "22      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "23      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "24      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "25      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "26      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "27      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "28      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "29      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "30      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "31      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "32      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "33      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "34      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "35      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "6      0.090892              0.050595              0.930481     0.369091   \n",
      "7      0.089555              0.053571              0.930481     0.367442   \n",
      "8      0.088342              0.053571              0.930481     0.365869   \n",
      "9      0.088731              0.053571              0.930481     0.364104   \n",
      "10     0.094133              0.053571              0.927808     0.362147   \n",
      "11     0.097632              0.053571              0.927808     0.360114   \n",
      "12     0.000000              0.000000              0.000000     0.000000   \n",
      "13     0.000000              0.000000              0.000000     0.000000   \n",
      "14     0.000000              0.000000              0.000000     0.000000   \n",
      "15     0.000000              0.000000              0.000000     0.000000   \n",
      "16     0.000000              0.000000              0.000000     0.000000   \n",
      "17     0.000000              0.000000              0.000000     0.000000   \n",
      "18     0.000000              0.000000              0.000000     0.000000   \n",
      "19     0.000000              0.000000              0.000000     0.000000   \n",
      "20     0.000000              0.000000              0.000000     0.000000   \n",
      "21     0.000000              0.000000              0.000000     0.000000   \n",
      "22     0.000000              0.000000              0.000000     0.000000   \n",
      "23     0.000000              0.000000              0.000000     0.000000   \n",
      "24     0.000000              0.000000              0.000000     0.000000   \n",
      "25     0.000000              0.000000              0.000000     0.000000   \n",
      "26     0.000000              0.000000              0.000000     0.000000   \n",
      "27     0.000000              0.000000              0.000000     0.000000   \n",
      "28     0.000000              0.000000              0.000000     0.000000   \n",
      "29     0.000000              0.000000              0.000000     0.000000   \n",
      "30     0.000000              0.000000              0.000000     0.000000   \n",
      "31     0.000000              0.000000              0.000000     0.000000   \n",
      "32     0.000000              0.000000              0.000000     0.000000   \n",
      "33     0.000000              0.000000              0.000000     0.000000   \n",
      "34     0.000000              0.000000              0.000000     0.000000   \n",
      "35     0.000000              0.000000              0.000000     0.000000   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "6      0.109676  16.0    16.0  \n",
      "7      0.109447  16.0    21.0  \n",
      "8      0.110040  16.0    26.0  \n",
      "9      0.111496  16.0    31.0  \n",
      "10     0.114154  16.0    36.0  \n",
      "11     0.117359  16.0    41.0  \n",
      "12     0.000000  16.0    46.0  \n",
      "13     0.000000  16.0    51.0  \n",
      "14     0.000000  16.0    56.0  \n",
      "15     0.000000  17.0     1.0  \n",
      "16     0.000000  17.0     6.0  \n",
      "17     0.000000  17.0    11.0  \n",
      "18     0.000000  17.0    16.0  \n",
      "19     0.000000  17.0    21.0  \n",
      "20     0.000000  17.0    26.0  \n",
      "21     0.000000  17.0    31.0  \n",
      "22     0.000000  17.0    36.0  \n",
      "23     0.000000  17.0    41.0  \n",
      "24     0.000000  17.0    46.0  \n",
      "25     0.000000  17.0    51.0  \n",
      "26     0.000000  17.0    56.0  \n",
      "27     0.000000  18.0     1.0  \n",
      "28     0.000000  18.0     6.0  \n",
      "29     0.000000  18.0    11.0  \n",
      "30     0.000000  18.0    16.0  \n",
      "31     0.000000  18.0    21.0  \n",
      "32     0.000000  18.0    26.0  \n",
      "33     0.000000  18.0    31.0  \n",
      "34     0.000000  18.0    36.0  \n",
      "35     0.000000  18.0    41.0  \n",
      "\n",
      " Target Shape: (24, 1)\n",
      "    GlucoseValue\n",
      "19     -0.286123\n",
      "20     -0.044196\n",
      "21      0.041190\n",
      "22      0.211963\n",
      "23      0.368504\n"
     ]
    }
   ],
   "source": [
    "encoder_file = get_first_file(encoder_dir)\n",
    "decoder_file = get_first_file(decoder_dir)\n",
    "target_file = get_first_file(target_dir)\n",
    "\n",
    "encoder_tensor = torch.load(encoder_file)\n",
    "decoder_tensor = torch.load(decoder_file)\n",
    "target_tensor = torch.load(target_file)\n",
    "\n",
    "\n",
    "encoder_df = pd.DataFrame(encoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "decoder_df = pd.DataFrame(decoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "target_df = pd.DataFrame(target_tensor.numpy(), columns=[\"GlucoseValue\"])\n",
    "\n",
    "print(f\"\\n Encoder Shape: {encoder_df.shape}\")\n",
    "print(encoder_df.tail())\n",
    "print(f\"\\n Decoder Shape: {decoder_df.shape}\")\n",
    "print(decoder_df.tail(30))\n",
    "print(f\"\\n Target Shape: {target_df.shape}\")\n",
    "print(target_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.    ReplaceBG Validation Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ptid, df in replace_cgm_validation_data.items():\n",
    "    df = df.copy()\n",
    "    df['real_value_flag'] = 1\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "\n",
    "    # Identify rows where TimeDiff is around 600 seconds (10 min)\n",
    "    mask = (df['TimeDiff'] > 595) & (df['TimeDiff'] < 605)\n",
    "    insert_rows = df[mask].copy()\n",
    "\n",
    "    if not insert_rows.empty:\n",
    "        # Modify new rows: set `real_value_flag = 0`, shift `DateTime`, and set `GlucoseValue = NaN`\n",
    "        insert_rows['real_value_flag'] = 0\n",
    "        insert_rows['DateTime'] -= pd.to_timedelta(5, unit='m')\n",
    "        insert_rows['GlucoseValue'] = np.nan\n",
    "\n",
    "        # Append new rows to the dataframe and sort\n",
    "    df = pd.concat([df, insert_rows]).sort_values(by='DateTime').reset_index(drop=True)\n",
    "\n",
    "    # Linearly interpolate the glucose value\n",
    "    df['GlucoseValue'] = df['GlucoseValue'].interpolate(method='linear')\n",
    "            \n",
    "    df['5min_change'] = df['GlucoseValue'].diff(1)\n",
    "    df['30min_change'] = df['GlucoseValue'].diff(6)\n",
    "    df['1hr_change'] = df['GlucoseValue'].diff(12)\n",
    "\n",
    "    df['1hr_mov_avg'] = df['GlucoseValue'].rolling(window=12).mean()\n",
    "    df['1hr_mov_std'] = df['GlucoseValue'].rolling(window=12).std()\n",
    "\n",
    "    df['1hr_largest_increase'] = df['5min_change'].rolling(window=12).max()\n",
    "    df['1hr_largest_decrease'] = df['5min_change'].rolling(window=12).min()\n",
    "\n",
    "    df['6hr_mov_avg'] = df['GlucoseValue'].rolling(window=72).mean()\n",
    "    df['6hr_mov_std'] = df['GlucoseValue'].rolling(window=72).std()\n",
    "\n",
    "    # create hour and minute columns~\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    # creates a rolling sum to determins complete data sequences suitable for use\n",
    "    # data sequences that hold missing data over  gaps greater that 10 minutes 5 seconds will be excluded\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "    df['TimeDiffFlag'] = df['TimeDiff'].apply(lambda x: 0 if x < 295 or x > 305 else 1)\n",
    "    df['RollingTimeDiffFlag'] = df['TimeDiffFlag'].rolling(window=96).sum()\n",
    "\n",
    "    # drop columns\n",
    "    df = df.drop(columns=['DateTime', 'TimeDiff', 'TimeDiffFlag', 'real_value_flag'])\n",
    "\n",
    "    df = df[288:]\n",
    "\n",
    "    replace_cgm_validation_data[ptid] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create slices of total input length\n",
    "\n",
    "replace_validation_slices = []\n",
    "\n",
    "for ptid, df in replace_cgm_validation_data.items():\n",
    "    if 'RollingTimeDiffFlag' not in df.columns:\n",
    "        continue  # Skip this dataframe if the column does not exist\n",
    "    rolling_flag_array = df[\"RollingTimeDiffFlag\"].to_numpy()  # Convert to NumPy array for fast indexing\n",
    "    num_rows = len(df)\n",
    "    starting_index = 0\n",
    "\n",
    "    while starting_index + slice_size <= num_rows:\n",
    "        if rolling_flag_array[starting_index + slice_size - 1] == slice_size:  # Use precomputed array\n",
    "            replace_validation_slices.append(df.iloc[starting_index:starting_index + slice_size])\n",
    "            starting_index += overlap  # Move by overlap\n",
    "        else:\n",
    "            starting_index += 1  # Ensure progress to avoid infinite loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242780"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replace_validation_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dict = {idx: slice for idx, slice in enumerate(replace_validation_slices)}\n",
    "\n",
    "target_size = int(len(validation_dict)/2)\n",
    "\n",
    "undersampled_validation_dict = undersample_dict(validation_dict, target_size)\n",
    "\n",
    "validation_list = list(undersampled_validation_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121390"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_validation_slices = []\n",
    "\n",
    "z_score_features = [\"GlucoseValue\", \"5min_change\", \"30min_change\", \"1hr_change\"]\n",
    "\n",
    "min_max_features = [\n",
    "    \"1hr_mov_avg\", \"6hr_mov_avg\",\n",
    "    \"1hr_mov_std\", \"6hr_mov_std\",\n",
    "    \"1hr_largest_increase\", \"1hr_largest_decrease\"\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(training_df[min_max_features])\n",
    "# Normalize using z-score normalization for all columns in col_list\n",
    "\n",
    "for slice in validation_list:\n",
    "    slice = slice.copy()\n",
    "    for col in z_score_features:\n",
    "        slice.loc[:, col] = (slice[col] - mean_std_dict[col][0]) / mean_std_dict[col][1]\n",
    "\n",
    "    for col in min_max_features:\n",
    "        slice.loc[:, col] = (slice[col] - min_max_dict[col][0]) / (min_max_dict[col][1] - min_max_dict[col][0])\n",
    "\n",
    "    slice.drop(columns=['RollingTimeDiffFlag', 'PtID'], inplace=True)\n",
    "\n",
    "    normalised_validation_slices.append(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121390"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalised_validation_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlucoseValue</th>\n",
       "      <th>5min_change</th>\n",
       "      <th>30min_change</th>\n",
       "      <th>1hr_change</th>\n",
       "      <th>1hr_mov_avg</th>\n",
       "      <th>1hr_mov_std</th>\n",
       "      <th>1hr_largest_increase</th>\n",
       "      <th>1hr_largest_decrease</th>\n",
       "      <th>6hr_mov_avg</th>\n",
       "      <th>6hr_mov_std</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>0.311580</td>\n",
       "      <td>0.533479</td>\n",
       "      <td>0.721646</td>\n",
       "      <td>0.527631</td>\n",
       "      <td>0.335405</td>\n",
       "      <td>0.045863</td>\n",
       "      <td>0.068452</td>\n",
       "      <td>0.946524</td>\n",
       "      <td>0.266805</td>\n",
       "      <td>0.127452</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>0.354273</td>\n",
       "      <td>0.533479</td>\n",
       "      <td>0.835864</td>\n",
       "      <td>0.619026</td>\n",
       "      <td>0.341160</td>\n",
       "      <td>0.052521</td>\n",
       "      <td>0.068452</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.268455</td>\n",
       "      <td>0.130830</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>0.382735</td>\n",
       "      <td>0.363715</td>\n",
       "      <td>0.797791</td>\n",
       "      <td>0.664723</td>\n",
       "      <td>0.347376</td>\n",
       "      <td>0.057111</td>\n",
       "      <td>0.068452</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.270335</td>\n",
       "      <td>0.134281</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>0.425428</td>\n",
       "      <td>0.533479</td>\n",
       "      <td>0.721646</td>\n",
       "      <td>0.710421</td>\n",
       "      <td>0.354052</td>\n",
       "      <td>0.061152</td>\n",
       "      <td>0.068452</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.272445</td>\n",
       "      <td>0.137911</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0.453890</td>\n",
       "      <td>0.363715</td>\n",
       "      <td>0.683574</td>\n",
       "      <td>0.733269</td>\n",
       "      <td>0.360958</td>\n",
       "      <td>0.063620</td>\n",
       "      <td>0.068452</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.274862</td>\n",
       "      <td>0.141337</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
       "5829      0.311580     0.533479      0.721646    0.527631     0.335405   \n",
       "5830      0.354273     0.533479      0.835864    0.619026     0.341160   \n",
       "5831      0.382735     0.363715      0.797791    0.664723     0.347376   \n",
       "5832      0.425428     0.533479      0.721646    0.710421     0.354052   \n",
       "5833      0.453890     0.363715      0.683574    0.733269     0.360958   \n",
       "\n",
       "      1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
       "5829     0.045863              0.068452              0.946524     0.266805   \n",
       "5830     0.052521              0.068452              0.949198     0.268455   \n",
       "5831     0.057111              0.068452              0.949198     0.270335   \n",
       "5832     0.061152              0.068452              0.949198     0.272445   \n",
       "5833     0.063620              0.068452              0.949198     0.274862   \n",
       "\n",
       "      6hr_mov_std  Hour  Minute  \n",
       "5829     0.127452     2      25  \n",
       "5830     0.130830     2      30  \n",
       "5831     0.134281     2      35  \n",
       "5832     0.137911     2      40  \n",
       "5833     0.141337     2      45  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first  5 rows of the first slice    \n",
    "normalised_validation_slices[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "encoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/validation/encoder_slices'\n",
    "decoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/validation/decoder_slices'\n",
    "target_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/validation/target_slices'\n",
    "\n",
    "\n",
    "os.makedirs(encoder_dir, exist_ok=True)\n",
    "os.makedirs(decoder_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for count, slice in enumerate(normalised_validation_slices):\n",
    "    # Define Encoder, Decoder, and Target sequences (Avoid Copying)\n",
    "    encoder_input = slice.iloc[:encoder_input_size]\n",
    "    target = slice.iloc[encoder_input_size: ]['GlucoseValue']\n",
    "\n",
    "\n",
    "    # Modify Decoder Input In-Place (Vectorized)\n",
    "    decoder_input = slice.iloc[-decoder_input_size:].copy().reset_index(drop=True)  # Copy last 36 rows\n",
    "    decoder_input.iloc[start_token_size:, decoder_input.columns.get_indexer(zero_out_columns)] = 0 \n",
    "    decoder_input = decoder_input.values  # Convert to NumPy array\n",
    "\n",
    "    # Define file paths\n",
    "    encoder_path = os.path.join(encoder_dir, f\"{count}.pt\")\n",
    "    decoder_path = os.path.join(decoder_dir, f\"{count}.pt\")\n",
    "    target_path = os.path.join(target_dir, f\"{count}.pt\")\n",
    "\n",
    "    # Save tensors without unnecessary copies\n",
    "    # Save tensors without unnecessary copies\n",
    "    torch.save(torch.tensor(encoder_input.values, dtype=torch.float32), encoder_path)\n",
    "    torch.save(torch.tensor(decoder_input, dtype=torch.float32), decoder_path)\n",
    "    torch.save(torch.tensor(target.values, dtype=torch.float32), target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Encoder Shape: (72, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "67     -0.371510     2.231121      1.102370    0.596177     0.184853   \n",
      "68     -0.314585     0.703244      1.178515    0.710421     0.191529   \n",
      "69     -0.271892     0.533479      1.178515    0.778967     0.198895   \n",
      "70     -0.158044     1.382300      1.445022    0.984604     0.208333   \n",
      "71     -0.129582     0.363715      1.330805    0.984604     0.217772   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "67     0.046773              0.092262              0.938503     0.202617   \n",
      "68     0.062851              0.092262              0.938503     0.203000   \n",
      "69     0.075359              0.092262              0.938503     0.203499   \n",
      "70     0.089531              0.092262              0.938503     0.204305   \n",
      "71     0.099880              0.092262              0.938503     0.205226   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "67     0.057447  10.0    39.0  \n",
      "68     0.058599  10.0    44.0  \n",
      "69     0.060206  10.0    49.0  \n",
      "70     0.063331  10.0    54.0  \n",
      "71     0.066757  10.0    59.0  \n",
      "\n",
      " Decoder Shape: (36, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "6      -0.556513     0.703244      0.455140    0.230599     0.179328   \n",
      "7      -0.371510     2.231121      1.102370    0.596177     0.184853   \n",
      "8      -0.314585     0.703244      1.178515    0.710421     0.191529   \n",
      "9      -0.271892     0.533479      1.178515    0.778967     0.198895   \n",
      "10     -0.158044     1.382300      1.445022    0.984604     0.208333   \n",
      "11     -0.129582     0.363715      1.330805    0.984604     0.217772   \n",
      "12      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "13      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "14      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "15      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "16      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "17      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "18      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "19      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "20      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "21      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "22      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "23      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "24      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "25      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "26      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "27      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "28      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "29      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "30      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "31      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "32      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "33      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "34      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "35      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "6      0.024877              0.068452              0.938503     0.202463   \n",
      "7      0.046773              0.092262              0.938503     0.202617   \n",
      "8      0.062851              0.092262              0.938503     0.203000   \n",
      "9      0.075359              0.092262              0.938503     0.203499   \n",
      "10     0.089531              0.092262              0.938503     0.204305   \n",
      "11     0.099880              0.092262              0.938503     0.205226   \n",
      "12     0.000000              0.000000              0.000000     0.000000   \n",
      "13     0.000000              0.000000              0.000000     0.000000   \n",
      "14     0.000000              0.000000              0.000000     0.000000   \n",
      "15     0.000000              0.000000              0.000000     0.000000   \n",
      "16     0.000000              0.000000              0.000000     0.000000   \n",
      "17     0.000000              0.000000              0.000000     0.000000   \n",
      "18     0.000000              0.000000              0.000000     0.000000   \n",
      "19     0.000000              0.000000              0.000000     0.000000   \n",
      "20     0.000000              0.000000              0.000000     0.000000   \n",
      "21     0.000000              0.000000              0.000000     0.000000   \n",
      "22     0.000000              0.000000              0.000000     0.000000   \n",
      "23     0.000000              0.000000              0.000000     0.000000   \n",
      "24     0.000000              0.000000              0.000000     0.000000   \n",
      "25     0.000000              0.000000              0.000000     0.000000   \n",
      "26     0.000000              0.000000              0.000000     0.000000   \n",
      "27     0.000000              0.000000              0.000000     0.000000   \n",
      "28     0.000000              0.000000              0.000000     0.000000   \n",
      "29     0.000000              0.000000              0.000000     0.000000   \n",
      "30     0.000000              0.000000              0.000000     0.000000   \n",
      "31     0.000000              0.000000              0.000000     0.000000   \n",
      "32     0.000000              0.000000              0.000000     0.000000   \n",
      "33     0.000000              0.000000              0.000000     0.000000   \n",
      "34     0.000000              0.000000              0.000000     0.000000   \n",
      "35     0.000000              0.000000              0.000000     0.000000   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "6      0.057011  10.0    34.0  \n",
      "7      0.057447  10.0    39.0  \n",
      "8      0.058599  10.0    44.0  \n",
      "9      0.060206  10.0    49.0  \n",
      "10     0.063331  10.0    54.0  \n",
      "11     0.066757  10.0    59.0  \n",
      "12     0.000000  11.0     4.0  \n",
      "13     0.000000  11.0     9.0  \n",
      "14     0.000000  11.0    14.0  \n",
      "15     0.000000  11.0    19.0  \n",
      "16     0.000000  11.0    24.0  \n",
      "17     0.000000  11.0    29.0  \n",
      "18     0.000000  11.0    34.0  \n",
      "19     0.000000  11.0    39.0  \n",
      "20     0.000000  11.0    44.0  \n",
      "21     0.000000  11.0    49.0  \n",
      "22     0.000000  11.0    54.0  \n",
      "23     0.000000  11.0    59.0  \n",
      "24     0.000000  12.0     4.0  \n",
      "25     0.000000  12.0     9.0  \n",
      "26     0.000000  12.0    14.0  \n",
      "27     0.000000  12.0    19.0  \n",
      "28     0.000000  12.0    24.0  \n",
      "29     0.000000  12.0    29.0  \n",
      "30     0.000000  12.0    34.0  \n",
      "31     0.000000  12.0    39.0  \n",
      "32     0.000000  12.0    44.0  \n",
      "33     0.000000  12.0    49.0  \n",
      "34     0.000000  12.0    54.0  \n",
      "35     0.000000  12.0    59.0  \n",
      "\n",
      " Target Shape: (24, 1)\n",
      "    GlucoseValue\n",
      "19     -0.158044\n",
      "20     -0.414203\n",
      "21     -0.513820\n",
      "22     -0.613437\n",
      "23     -0.798441\n"
     ]
    }
   ],
   "source": [
    "encoder_file = get_first_file(encoder_dir)\n",
    "decoder_file = get_first_file(decoder_dir)\n",
    "target_file = get_first_file(target_dir)\n",
    "\n",
    "encoder_tensor = torch.load(encoder_file)\n",
    "decoder_tensor = torch.load(decoder_file)\n",
    "target_tensor = torch.load(target_file)\n",
    "\n",
    "\n",
    "encoder_df = pd.DataFrame(encoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "decoder_df = pd.DataFrame(decoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "target_df = pd.DataFrame(target_tensor.numpy(), columns=[\"GlucoseValue\"])\n",
    "\n",
    "print(f\"\\n Encoder Shape: {encoder_df.shape}\")\n",
    "print(encoder_df.tail())\n",
    "print(f\"\\n Decoder Shape: {decoder_df.shape}\")\n",
    "print(decoder_df.tail(30))\n",
    "print(f\"\\n Target Shape: {target_df.shape}\")\n",
    "print(target_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.    ReplaceBG Test Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ptid, df in replace_cgm_test_data.items():\n",
    "    df = df.copy()\n",
    "    df['real_value_flag'] = 1\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "\n",
    "    # Identify rows where TimeDiff is around 600 seconds (10 min)\n",
    "    mask = (df['TimeDiff'] > 595) & (df['TimeDiff'] < 605)\n",
    "    insert_rows = df[mask].copy()\n",
    "\n",
    "    if not insert_rows.empty:\n",
    "        # Modify new rows: set `real_value_flag = 0`, shift `DateTime`, and set `GlucoseValue = NaN`\n",
    "        insert_rows['real_value_flag'] = 0\n",
    "        insert_rows['DateTime'] -= pd.to_timedelta(5, unit='m')\n",
    "        insert_rows['GlucoseValue'] = np.nan\n",
    "\n",
    "        # Append new rows to the dataframe and sort\n",
    "    df = pd.concat([df, insert_rows]).sort_values(by='DateTime').reset_index(drop=True)\n",
    "\n",
    "    # Linearly interpolate the glucose value\n",
    "    df['GlucoseValue'] = df['GlucoseValue'].interpolate(method='linear')\n",
    "            \n",
    "    df['5min_change'] = df['GlucoseValue'].diff(1)\n",
    "    df['30min_change'] = df['GlucoseValue'].diff(6)\n",
    "    df['1hr_change'] = df['GlucoseValue'].diff(12)\n",
    "\n",
    "    df['1hr_mov_avg'] = df['GlucoseValue'].rolling(window=12).mean()\n",
    "    df['1hr_mov_std'] = df['GlucoseValue'].rolling(window=12).std()\n",
    "\n",
    "    df['1hr_largest_increase'] = df['5min_change'].rolling(window=12).max()\n",
    "    df['1hr_largest_decrease'] = df['5min_change'].rolling(window=12).min()\n",
    "\n",
    "    df['6hr_mov_avg'] = df['GlucoseValue'].rolling(window=72).mean()\n",
    "    df['6hr_mov_std'] = df['GlucoseValue'].rolling(window=72).std()\n",
    "\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "    df['TimeDiffFlag'] = df['TimeDiff'].apply(lambda x: 0 if x < 295 or x > 305 else 1)\n",
    "    df['RollingTimeDiffFlag'] = df['TimeDiffFlag'].rolling(window=96).sum()\n",
    "\n",
    "    # drop columns\n",
    "    df = df.drop(columns=['DateTime', 'TimeDiff', 'TimeDiffFlag', 'real_value_flag'])\n",
    "\n",
    "    df = df[288:]\n",
    "\n",
    "    replace_cgm_test_data[ptid] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_test_slices = []\n",
    "\n",
    "for ptid, df in replace_cgm_test_data.items():\n",
    "    if 'RollingTimeDiffFlag' not in df.columns:\n",
    "        continue  # Skip this dataframe if the column does not exist\n",
    "    rolling_flag_array = df[\"RollingTimeDiffFlag\"].to_numpy()  # Convert to NumPy array for fast indexing\n",
    "    num_rows = len(df)\n",
    "    starting_index = 0\n",
    "\n",
    "    while starting_index + slice_size <= num_rows:\n",
    "        if rolling_flag_array[starting_index + slice_size - 1] == slice_size:  # Use precomputed array\n",
    "            replace_test_slices.append(df.iloc[starting_index:starting_index + slice_size])\n",
    "            starting_index += overlap  # Move by overlap\n",
    "        else:\n",
    "            starting_index += 1  # Ensure progress to avoid infinite loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271190"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replace_test_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {idx: slice for idx, slice in enumerate(replace_test_slices)}\n",
    "\n",
    "target_size = int(len(test_dict)/2)\n",
    "\n",
    "undersampled_test_dict = undersample_dict(test_dict, target_size)\n",
    "\n",
    "test_list = list(undersampled_test_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_test_slices = []\n",
    "\n",
    "z_score_features = [\"GlucoseValue\", \"5min_change\", \"30min_change\", \"1hr_change\"]\n",
    "\n",
    "min_max_features = [\n",
    "    \"1hr_mov_avg\", \"6hr_mov_avg\",\n",
    "    \"1hr_mov_std\", \"6hr_mov_std\",\n",
    "    \"1hr_largest_increase\", \"1hr_largest_decrease\"\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(training_df[min_max_features])\n",
    "# Normalize using z-score normalization for all columns in col_list\n",
    "\n",
    "for slice in test_list:\n",
    "    slice = slice.copy()\n",
    "    for col in z_score_features:\n",
    "        slice.loc[:, col] = (slice[col] - mean_std_dict[col][0]) / mean_std_dict[col][1]\n",
    "\n",
    "    for col in min_max_features:\n",
    "        slice.loc[:, col] = (slice[col] - min_max_dict[col][0]) / (min_max_dict[col][1] - min_max_dict[col][0])\n",
    "\n",
    "    slice.drop(columns=['RollingTimeDiffFlag', 'PtID'], inplace=True)\n",
    "\n",
    "    normalised_test_slices.append(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlucoseValue</th>\n",
       "      <th>5min_change</th>\n",
       "      <th>30min_change</th>\n",
       "      <th>1hr_change</th>\n",
       "      <th>1hr_mov_avg</th>\n",
       "      <th>1hr_mov_std</th>\n",
       "      <th>1hr_largest_increase</th>\n",
       "      <th>1hr_largest_decrease</th>\n",
       "      <th>6hr_mov_avg</th>\n",
       "      <th>6hr_mov_std</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>0.966208</td>\n",
       "      <td>0.024187</td>\n",
       "      <td>-0.154019</td>\n",
       "      <td>1.373032</td>\n",
       "      <td>0.481584</td>\n",
       "      <td>0.094836</td>\n",
       "      <td>0.101190</td>\n",
       "      <td>0.906417</td>\n",
       "      <td>0.226941</td>\n",
       "      <td>0.299835</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>0.980439</td>\n",
       "      <td>0.193951</td>\n",
       "      <td>-0.344381</td>\n",
       "      <td>1.030302</td>\n",
       "      <td>0.491483</td>\n",
       "      <td>0.070121</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.906417</td>\n",
       "      <td>0.231085</td>\n",
       "      <td>0.307896</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>0.951977</td>\n",
       "      <td>-0.315342</td>\n",
       "      <td>-0.382453</td>\n",
       "      <td>0.710421</td>\n",
       "      <td>0.498158</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>0.086310</td>\n",
       "      <td>0.906417</td>\n",
       "      <td>0.235267</td>\n",
       "      <td>0.315141</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>0.809666</td>\n",
       "      <td>-1.673455</td>\n",
       "      <td>-0.154019</td>\n",
       "      <td>0.230599</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.042833</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.906417</td>\n",
       "      <td>0.239142</td>\n",
       "      <td>0.320555</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>0.681587</td>\n",
       "      <td>-1.503691</td>\n",
       "      <td>-0.420525</td>\n",
       "      <td>-0.180677</td>\n",
       "      <td>0.497698</td>\n",
       "      <td>0.052108</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.906417</td>\n",
       "      <td>0.242787</td>\n",
       "      <td>0.324506</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
       "2741      0.966208     0.024187     -0.154019    1.373032     0.481584   \n",
       "2742      0.980439     0.193951     -0.344381    1.030302     0.491483   \n",
       "2743      0.951977    -0.315342     -0.382453    0.710421     0.498158   \n",
       "2744      0.809666    -1.673455     -0.154019    0.230599     0.500000   \n",
       "2745      0.681587    -1.503691     -0.420525   -0.180677     0.497698   \n",
       "\n",
       "      1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
       "2741     0.094836              0.101190              0.906417     0.226941   \n",
       "2742     0.070121              0.089286              0.906417     0.231085   \n",
       "2743     0.050433              0.086310              0.906417     0.235267   \n",
       "2744     0.042833              0.080357              0.906417     0.239142   \n",
       "2745     0.052108              0.077381              0.906417     0.242787   \n",
       "\n",
       "      6hr_mov_std  Hour  Minute  \n",
       "2741     0.299835     9       5  \n",
       "2742     0.307896     9      10  \n",
       "2743     0.315141     9      15  \n",
       "2744     0.320555     9      20  \n",
       "2745     0.324506     9      25  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_test_slices[0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/testing/encoder_slices'\n",
    "decoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/testing/decoder_slices'\n",
    "target_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/testing/target_slices'\n",
    "\n",
    "os.makedirs(encoder_dir, exist_ok=True)\n",
    "os.makedirs(decoder_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for count, slice in enumerate(normalised_test_slices):\n",
    "    # Define Encoder, Decoder, and Target sequences (Avoid Copying)\n",
    "    encoder_input = slice.iloc[:encoder_input_size]\n",
    "    target = slice.iloc[encoder_input_size: ]['GlucoseValue']\n",
    "\n",
    "    # Modify Decoder Input In-Place (Vectorized)\n",
    "    decoder_input = slice.iloc[-decoder_input_size:].copy().reset_index(drop=True)  # Copy last 36 rows\n",
    "    decoder_input.iloc[start_token_size:, decoder_input.columns.get_indexer(zero_out_columns)] = 0 \n",
    "    decoder_input = decoder_input.values  # Convert to NumPy array\n",
    "\n",
    "    # Define file paths\n",
    "    encoder_path = os.path.join(encoder_dir, f\"{count}.pt\")\n",
    "    decoder_path = os.path.join(decoder_dir, f\"{count}.pt\")\n",
    "    target_path = os.path.join(target_dir, f\"{count}.pt\")\n",
    "\n",
    "    # Save tensors without unnecessary copies\n",
    "    torch.save(torch.tensor(encoder_input.values, dtype=torch.float32), encoder_path)\n",
    "    torch.save(torch.tensor(decoder_input, dtype=torch.float32), decoder_path)\n",
    "    torch.save(torch.tensor(target.values, dtype=torch.float32), target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Encoder Shape: (72, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "67      1.393139     0.193951      0.378995    0.459086     0.572053   \n",
      "68      1.378908    -0.145577      0.302850    0.139204     0.572974   \n",
      "69      1.364677    -0.145577      0.226705    0.093507     0.573435   \n",
      "70      1.407370     0.533479      0.264778    0.162053     0.574586   \n",
      "71      1.378908    -0.315342      0.074416    0.162053     0.575737   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "67     0.017167              0.092262               0.94385     0.569406   \n",
      "68     0.018441              0.062500               0.94385     0.570826   \n",
      "69     0.018961              0.062500               0.94385     0.572169   \n",
      "70     0.021150              0.062500               0.94385     0.573665   \n",
      "71     0.021372              0.062500               0.94385     0.575199   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "67     0.066996   4.0    58.0  \n",
      "68     0.063112   5.0     3.0  \n",
      "69     0.059058   5.0     8.0  \n",
      "70     0.054357   5.0    13.0  \n",
      "71     0.047831   5.0    18.0  \n",
      "\n",
      " Decoder Shape: (36, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "6       1.378908     0.193951      0.302850    0.276296     0.567910   \n",
      "7       1.393139     0.193951      0.378995    0.459086     0.572053   \n",
      "8       1.378908    -0.145577      0.302850    0.139204     0.572974   \n",
      "9       1.364677    -0.145577      0.226705    0.093507     0.573435   \n",
      "10      1.407370     0.533479      0.264778    0.162053     0.574586   \n",
      "11      1.378908    -0.315342      0.074416    0.162053     0.575737   \n",
      "12      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "13      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "14      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "15      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "16      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "17      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "18      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "19      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "20      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "21      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "22      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "23      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "24      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "25      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "26      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "27      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "28      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "29      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "30      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "31      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "32      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "33      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "34      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "35      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "6      0.026147              0.092262              0.930481     0.567986   \n",
      "7      0.017167              0.092262              0.943850     0.569406   \n",
      "8      0.018441              0.062500              0.943850     0.570826   \n",
      "9      0.018961              0.062500              0.943850     0.572169   \n",
      "10     0.021150              0.062500              0.943850     0.573665   \n",
      "11     0.021372              0.062500              0.943850     0.575199   \n",
      "12     0.000000              0.000000              0.000000     0.000000   \n",
      "13     0.000000              0.000000              0.000000     0.000000   \n",
      "14     0.000000              0.000000              0.000000     0.000000   \n",
      "15     0.000000              0.000000              0.000000     0.000000   \n",
      "16     0.000000              0.000000              0.000000     0.000000   \n",
      "17     0.000000              0.000000              0.000000     0.000000   \n",
      "18     0.000000              0.000000              0.000000     0.000000   \n",
      "19     0.000000              0.000000              0.000000     0.000000   \n",
      "20     0.000000              0.000000              0.000000     0.000000   \n",
      "21     0.000000              0.000000              0.000000     0.000000   \n",
      "22     0.000000              0.000000              0.000000     0.000000   \n",
      "23     0.000000              0.000000              0.000000     0.000000   \n",
      "24     0.000000              0.000000              0.000000     0.000000   \n",
      "25     0.000000              0.000000              0.000000     0.000000   \n",
      "26     0.000000              0.000000              0.000000     0.000000   \n",
      "27     0.000000              0.000000              0.000000     0.000000   \n",
      "28     0.000000              0.000000              0.000000     0.000000   \n",
      "29     0.000000              0.000000              0.000000     0.000000   \n",
      "30     0.000000              0.000000              0.000000     0.000000   \n",
      "31     0.000000              0.000000              0.000000     0.000000   \n",
      "32     0.000000              0.000000              0.000000     0.000000   \n",
      "33     0.000000              0.000000              0.000000     0.000000   \n",
      "34     0.000000              0.000000              0.000000     0.000000   \n",
      "35     0.000000              0.000000              0.000000     0.000000   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "6      0.070276   4.0    53.0  \n",
      "7      0.066996   4.0    58.0  \n",
      "8      0.063112   5.0     3.0  \n",
      "9      0.059058   5.0     8.0  \n",
      "10     0.054357   5.0    13.0  \n",
      "11     0.047831   5.0    18.0  \n",
      "12     0.000000   5.0    23.0  \n",
      "13     0.000000   5.0    28.0  \n",
      "14     0.000000   5.0    33.0  \n",
      "15     0.000000   5.0    38.0  \n",
      "16     0.000000   5.0    43.0  \n",
      "17     0.000000   5.0    48.0  \n",
      "18     0.000000   5.0    53.0  \n",
      "19     0.000000   5.0    58.0  \n",
      "20     0.000000   6.0     3.0  \n",
      "21     0.000000   6.0     8.0  \n",
      "22     0.000000   6.0    13.0  \n",
      "23     0.000000   6.0    18.0  \n",
      "24     0.000000   6.0    23.0  \n",
      "25     0.000000   6.0    28.0  \n",
      "26     0.000000   6.0    33.0  \n",
      "27     0.000000   6.0    38.0  \n",
      "28     0.000000   6.0    43.0  \n",
      "29     0.000000   6.0    48.0  \n",
      "30     0.000000   6.0    53.0  \n",
      "31     0.000000   6.0    58.0  \n",
      "32     0.000000   7.0     3.0  \n",
      "33     0.000000   7.0     8.0  \n",
      "34     0.000000   7.0    13.0  \n",
      "35     0.000000   7.0    18.0  \n",
      "\n",
      " Target Shape: (24, 1)\n",
      "    GlucoseValue\n",
      "19      0.823897\n",
      "20      0.795435\n",
      "21      0.809666\n",
      "22      0.795435\n",
      "23      0.781204\n"
     ]
    }
   ],
   "source": [
    "encoder_file = get_first_file(encoder_dir)\n",
    "decoder_file = get_first_file(decoder_dir)\n",
    "target_file = get_first_file(target_dir)\n",
    "\n",
    "encoder_tensor = torch.load(encoder_file)\n",
    "decoder_tensor = torch.load(decoder_file)\n",
    "target_tensor = torch.load(target_file)\n",
    "\n",
    "encoder_df = pd.DataFrame(encoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "decoder_df = pd.DataFrame(decoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "target_df = pd.DataFrame(target_tensor.numpy(), columns=[\"GlucoseValue\"])\n",
    "\n",
    "print(f\"\\n Encoder Shape: {encoder_df.shape}\")\n",
    "print(encoder_df.tail())\n",
    "print(f\"\\n Decoder Shape: {decoder_df.shape}\")\n",
    "print(decoder_df.tail(30))\n",
    "print(f\"\\n Target Shape: {target_df.shape}\")\n",
    "print(target_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
