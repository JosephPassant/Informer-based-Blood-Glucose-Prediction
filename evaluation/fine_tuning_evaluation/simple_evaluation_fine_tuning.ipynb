{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation of Feature Enhancement**  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Contents**\n",
    "1. [Importing Libraries](evaluation_of_feature_enhancement.ipynb#1-importing-libraries)  \n",
    "   \n",
    "2. [Load Results](evaluation_of_feature_enhancement.ipynb#2-load-results)  \n",
    "   \n",
    "3. [RMSE and MAE](evaluation_of_feature_enhancement.ipynb#3-rmse-and-mae)  \n",
    "   - 3.1 [RMSE and MAE Statistical Analysis](evaluation_of_feature_enhancement.ipynb#3.1-rmse-and-mae-statistical-analysis)  \n",
    "  \n",
    "4. [CG-EGA Summary Classification](evaluation_of_feature_enhancement.ipynb#4-cg-ega-summary-classification)\n",
    "   - 4.1 [CG-EGA Summary Classification Statistical Analysis](evaluation_of_feature_enhancement.ipynb#4.1-cg-ega-summary-classification-statistical-analysis)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(current_dir, \"../../\"))\n",
    "\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, \"shared_utilities\"))\n",
    "try:\n",
    "\tfrom metrics import *\n",
    "except ModuleNotFoundError:\n",
    "\tprint(\"Module 'metrics' not found. Please ensure it exists in the 'shared_utilities' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptid_list = [540, 544, 552, 559, 563, 567, 570, 575, 584, 588, 591, 596]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/josephpassant/BG_Prediction/models/jpformer/fine_tuning_development_files/base_model_evaluation/patient_540/base_model_eval/patient_540_base_model_detailed_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m aggregate_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ptid \u001b[38;5;129;01min\u001b[39;00m ptid_list:\n\u001b[0;32m---> 10\u001b[0m     base_eval_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_eval_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatient_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mptid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_model_eval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatient_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mptid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_base_model_detailed_test.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     base_overall_dict[ptid] \u001b[38;5;241m=\u001b[39m base_eval_df\n\u001b[1;32m     14\u001b[0m all_base_dfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(base_overall_dict\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jpformer/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jpformer/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jpformer/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jpformer/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jpformer/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/josephpassant/BG_Prediction/models/jpformer/fine_tuning_development_files/base_model_evaluation/patient_540/base_model_eval/patient_540_base_model_detailed_test.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"Base Model Evaluation Files\"\"\"\n",
    "\n",
    "base_eval_dir = os.path.join(PROJECT_ROOT, \"evaluation\n",
    "\n",
    "base_overall_dict = {}\n",
    "\n",
    "aggregate_df = pd.DataFrame()\n",
    "\n",
    "for ptid in ptid_list:\n",
    "    base_eval_df = pd.read_csv(os.path.join(base_eval_dir, f\"patient_{ptid}\", \"base_model_eval\", f\"patient_{ptid}_base_model_detailed_test.csv\"))\n",
    "    base_overall_dict[ptid] = base_eval_df\n",
    "\n",
    "\n",
    "all_base_dfs = list(base_overall_dict.values())\n",
    "\n",
    "aggregate_base_df = pd.concat(all_base_dfs, axis=0)\n",
    "aggregate_base_df = aggregate_base_df.reset_index(drop=True)\n",
    "\n",
    "aggregate_base_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_dir = os.path.join(PROJECT_ROOT, \"models/jpformer/fine_tuning_development_files/loss_function_weights_lowest\")\n",
    "\n",
    "fine_tuned_dict = {}\n",
    "\n",
    "for ptid in ptid_list:\n",
    "    fine_tuned_df = pd.read_csv(os.path.join(fine_tuned_dir, f\"patient_{ptid}/fine_tuning_eval/patient_{ptid}_detailed_test_results.csv\"))\n",
    "    fine_tuned_dict[ptid] = fine_tuned_df\n",
    "\n",
    "\n",
    "\n",
    "all_fine_tuned_dfs = list(fine_tuned_dict.values())\n",
    "\n",
    "aggregate_fine_tuned_df = pd.concat(all_fine_tuned_dfs, axis=0)\n",
    "aggregate_fine_tuned_df = aggregate_fine_tuned_df.reset_index(drop=True)\n",
    "\n",
    "aggregate_fine_tuned_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Aggregate Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. RMSE and MAPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple RMSE function\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "base_rmse = calculate_rmse(aggregate_base_df['true_glucose'], aggregate_base_df['predicted_glucose'])\n",
    "fine_tuned_rmse = calculate_rmse(aggregate_fine_tuned_df['true_glucose'], aggregate_fine_tuned_df['predicted_glucose'])\n",
    "\n",
    "\n",
    "\n",
    "def mape(predictions, targets):\n",
    "    return np.mean(np.abs((predictions - targets) / targets)) * 100\n",
    "\n",
    "base_mape = mape(aggregate_base_df['predicted_glucose'], aggregate_base_df['true_glucose'])\n",
    "fine_tuned_mape = mape(aggregate_fine_tuned_df['predicted_glucose'], aggregate_fine_tuned_df['true_glucose'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table with model in 1st column and rmse and mae in 2nd and 3rd columns\n",
    "rmse_mape_table = pd.DataFrame({'model': ['base model', 'fine-tuned models'], 'MSE': [base_rmse, fine_tuned_rmse], 'MAPE': [base_mape, fine_tuned_mape]})\n",
    "rmse_mape_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot comparison column chart for RMSE and MAE and display in a 2x1 grid\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "# Define custom colors for the models\n",
    "model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "palette = [model1_color, model2_color]\n",
    "\n",
    "# Plot RMSE\n",
    "sns.barplot(x='model', y='MSE', data=rmse_mape_table, ax=axs[0], hue='model', palette=palette, legend=False)\n",
    "axs[0].set_title('RMSE', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[0].set_ylabel('RMSE (mg/dL)', fontsize=14)\n",
    "axs[0].set_xlabel('')  # Remove x-axis label\n",
    "\n",
    "# Plot MAE\n",
    "sns.barplot(x='model', y='MAPE', data=rmse_mape_table, ax=axs[1], hue='model', palette=palette, legend=False)\n",
    "axs[1].set_title('MAPE', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[1].set_ylabel('MAPE', fontsize=14)\n",
    "axs[1].set_xlabel('')  # Remove x-axis label\n",
    "\n",
    "# Set y-axis limits and add data labels\n",
    "for ax in axs:\n",
    "    ax.set_ylim(0, 50)  # Adjusted to better fit the data range\n",
    "    # Make tick labels smaller\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    # Add data labels\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f\"{p.get_height():.1f}\", \n",
    "                  (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                  ha='center', va='bottom', fontsize=14)\n",
    "    # Remove top and right borders\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)  # Adjust to make room for the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 RMSE and MAPE Statistical Analysis**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ttests(no_fe_model, fe_model, glycemic_region, model1_name=\"Model w/o FE\", model2_name=\"Model w/ FE\"):\n",
    "    print(f\"\\nüîç Running t-test for {model1_name} vs {model2_name} ({glycemic_region.capitalize()}glycaemic Range Performance):\\n\")\n",
    "\n",
    "    # Copy data to avoid modifying the originals\n",
    "    df1 = no_fe_model.copy()\n",
    "    df2 = fe_model.copy()\n",
    "\n",
    "    # Filter based on glycemic region\n",
    "    glycemic_region = glycemic_region.lower()\n",
    "    if glycemic_region == 'hypo':\n",
    "        df1 = df1[df1['glycemic_region'] == 'hypo']\n",
    "        df2 = df2[df2['glycemic_region'] == 'hypo']\n",
    "    elif glycemic_region == 'hyper':\n",
    "        df1 = df1[df1['glycemic_region'] == 'hyper']\n",
    "        df2 = df2[df2['glycemic_region'] == 'hyper']\n",
    "    elif glycemic_region == 'eu':\n",
    "        df1 = df1[df1['glycemic_region'] == 'eu']\n",
    "        df2 = df2[df2['glycemic_region'] == 'eu']\n",
    "    else:\n",
    "        pass  # Use all data if 'overall' or invalid\n",
    "\n",
    "    # Calculate errors\n",
    "    df1['absolute_error'] = np.abs(df1['true_glucose'] - df1['predicted_glucose'])\n",
    "    df2['absolute_error'] = np.abs(df2['true_glucose'] - df2['predicted_glucose'])\n",
    "\n",
    "    df1['squared_error'] = df1['absolute_error'] ** 2\n",
    "    df2['squared_error'] = df2['absolute_error'] ** 2\n",
    "    \n",
    "    # Calculate percentage errors for MAPE\n",
    "    df1['percentage_error'] = np.abs((df1['true_glucose'] - df1['predicted_glucose']) / df1['true_glucose']) * 100\n",
    "    df2['percentage_error'] = np.abs((df2['true_glucose'] - df2['predicted_glucose']) / df2['true_glucose']) * 100\n",
    "\n",
    "    # Use Welch's t-test (unpaired, unequal variance)\n",
    "    tt_mse, p_mse = stats.ttest_ind(df1['squared_error'], df2['squared_error'], equal_var=False)\n",
    "    tt_mape, p_mape = stats.ttest_ind(df1['percentage_error'], df2['percentage_error'], equal_var=False)\n",
    "\n",
    "    # Format results\n",
    "    results = pd.DataFrame({\n",
    "        \"Metric\": [\"RMSE\", \"MAPE\"],\n",
    "        \"t-statistic\": [tt_mse, tt_mape],\n",
    "        \"p-value\": [p_mse, p_mape],\n",
    "        \"Significance (p < 0.05)\": [p_mse < 0.05, p_mape < 0.05]\n",
    "    })\n",
    "\n",
    "    display(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_ttests = return_ttests(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region=\"overall\", model1_name=\"Base Model\", model2_name=\"Fine-tuned Model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. CG-EGA Summary Classifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD BINARY COLUM FOR ACCURATE PREDICTION BASED ON CGEGA_CLASS COLUMN\n",
    "aggregate_base_df['AP'] = np.where(aggregate_base_df['CG_EGA_Class'] == 'AP', 1, 0)\n",
    "aggregate_base_df['BE'] = np.where(aggregate_base_df['CG_EGA_Class'] == 'BE', 1, 0)\n",
    "aggregate_base_df['EP'] = np.where(aggregate_base_df['CG_EGA_Class'] == 'EP', 1, 0)\n",
    "\n",
    "\n",
    "aggregate_fine_tuned_df['AP'] = np.where(aggregate_fine_tuned_df['CG_EGA_Class'] == 'AP', 1, 0)\n",
    "aggregate_fine_tuned_df['BE'] = np.where(aggregate_fine_tuned_df['CG_EGA_Class'] == 'BE', 1, 0)\n",
    "aggregate_fine_tuned_df['EP'] = np.where(aggregate_fine_tuned_df['CG_EGA_Class'] == 'EP', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# Create summary tables for overall, hypo, eu, and hyper glycaemic regions\n",
    "regions = ['overall', 'hypo', 'eu', 'hyper']\n",
    "summary_tables = {}\n",
    "\n",
    "for region in regions:\n",
    "    # Initialize empty DataFrame with specific dtypes to avoid warning\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Model': pd.Series(dtype='object'),\n",
    "        'AP': pd.Series(dtype='int64'), \n",
    "        'BE': pd.Series(dtype='int64'), \n",
    "        'EP': pd.Series(dtype='int64'), \n",
    "        'Count': pd.Series(dtype='int64'),\n",
    "        'AP_pct': pd.Series(dtype='float64'), \n",
    "        'BE_pct': pd.Series(dtype='float64'), \n",
    "        'EP_pct': pd.Series(dtype='float64')\n",
    "    })\n",
    "    \n",
    "    # Process each model\n",
    "    for model, df in zip(['base model', 'fine-tuned models'], \n",
    "                        [aggregate_base_df, aggregate_fine_tuned_df]):\n",
    "        \n",
    "        # Filter for region if not overall\n",
    "        if region != 'overall':\n",
    "            region_df = df[df['glycemic_region'] == region]\n",
    "        else:\n",
    "            region_df = df\n",
    "            \n",
    "        # Calculate counts\n",
    "        ap_count = region_df['AP'].sum()\n",
    "        be_count = region_df['BE'].sum()\n",
    "        ep_count = region_df['EP'].sum()\n",
    "        total_count = len(region_df)\n",
    "        \n",
    "        # Create a new row as a dictionary and append it to the DataFrame\n",
    "        new_row = {\n",
    "            'Model': model, \n",
    "            'AP': ap_count, \n",
    "            'BE': be_count, \n",
    "            'EP': ep_count, \n",
    "            'Count': total_count,\n",
    "            'AP:EP': ap_count / ep_count if ep_count != 0 else np.nan,\n",
    "            'AP_pct': ap_count / total_count * 100, \n",
    "            'BE_pct': be_count / total_count * 100, \n",
    "            'EP_pct': ep_count / total_count * 100\n",
    "        }\n",
    "        summary_df = pd.concat([summary_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    summary_tables[region] = summary_df\n",
    "\n",
    "# Create 1x2 grid figure with custom width ratios\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), gridspec_kw={'width_ratios': [1, 2]})\n",
    "\n",
    "# PLOT 1: Overall AP:EP ratio (left panel)\n",
    "sns.barplot(\n",
    "    x='Model', \n",
    "    y='AP:EP', \n",
    "    data=summary_tables['overall'], \n",
    "    ax=axs[0], \n",
    "    palette=palette,\n",
    "    hue='Model',\n",
    "    legend=False\n",
    ")\n",
    "axs[0].set_title('Overall AP:EP Ratio', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[0].set_ylabel('AP:EP Ratio', fontsize=14)\n",
    "axs[0].set_xlabel('')  # Remove x-axis label\n",
    "axs[0].tick_params(axis='both', labelsize=14)\n",
    "axs[0].set_ylim(0, 100)  # Set y-axis range from 0 to 100\n",
    "\n",
    "# Add data labels\n",
    "for p in axs[0].patches:\n",
    "    axs[0].annotate(f\"{p.get_height():.1f}\", \n",
    "                  (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                  ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# PLOT 2: AP:EP by Glycemic Region (right panel)\n",
    "# Create a new dataframe that combines the regional data for plotting\n",
    "regional_data = pd.concat([\n",
    "    summary_tables['hypo'][['Model', 'AP:EP']].assign(Region='Hypo'),\n",
    "    summary_tables['eu'][['Model', 'AP:EP']].assign(Region='Eu'),\n",
    "    summary_tables['hyper'][['Model', 'AP:EP']].assign(Region='Hyper')\n",
    "])\n",
    "\n",
    "sns.barplot(\n",
    "    x='Region', \n",
    "    y='AP:EP', \n",
    "    hue='Model',\n",
    "    data=regional_data, \n",
    "    ax=axs[1], \n",
    "    palette=palette\n",
    ")\n",
    "axs[1].set_title('AP:EP Ratio Across Glycemic Regions', fontsize=14, fontweight='bold')\n",
    "axs[1].set_ylabel('AP:EP Ratio', fontsize=12)\n",
    "axs[1].set_xlabel('Glycemic Region', fontsize=12)\n",
    "axs[1].tick_params(axis='both', labelsize=10)\n",
    "axs[1].set_ylim(0, 100)  # Set y-axis range from 0 to 100\n",
    "\n",
    "# Add data labels to the second chart\n",
    "for container in axs[1].containers:\n",
    "    axs[1].bar_label(container, fmt='%.1f', fontsize=11, fontweight='bold')\n",
    "\n",
    "\n",
    "# Add legend to the right plot\n",
    "axs[1].legend(title='Model', fontsize=9, title_fontsize=10)\n",
    "\n",
    "# Remove top and right borders\n",
    "sns.despine(ax=axs[0])\n",
    "sns.despine(ax=axs[1])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # Adjust to make room for the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom colors for the models\n",
    "model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "palette = [model1_color, model2_color]\n",
    "\n",
    "# Create summary tables for overall, hypo, eu, and hyper glycaemic regions\n",
    "regions = ['overall', 'hypo', 'eu', 'hyper']\n",
    "summary_tables = {}\n",
    "\n",
    "for region in regions:\n",
    "    # Initialize empty DataFrame with specific dtypes to avoid warning\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Model': pd.Series(dtype='object'),\n",
    "        'AP': pd.Series(dtype='int64'), \n",
    "        'BE': pd.Series(dtype='int64'), \n",
    "        'EP': pd.Series(dtype='int64'), \n",
    "        'Count': pd.Series(dtype='int64'),\n",
    "        'AP_pct': pd.Series(dtype='float64'), \n",
    "        'BE_pct': pd.Series(dtype='float64'), \n",
    "        'EP_pct': pd.Series(dtype='float64')\n",
    "    })\n",
    "    \n",
    "    # Process each model\n",
    "    for model, df in zip(['Population\\nJPFormer', 'Personalised\\nJPFormer'], \n",
    "                        [aggregate_base_df, aggregate_fine_tuned_df]):\n",
    "        \n",
    "        # Filter for region if not overall\n",
    "        if region != 'overall':\n",
    "            region_df = df[df['glycemic_region'] == region]\n",
    "        else:\n",
    "            region_df = df\n",
    "            \n",
    "        # Calculate counts\n",
    "        ap_count = region_df['AP'].sum()\n",
    "        be_count = region_df['BE'].sum()\n",
    "        ep_count = region_df['EP'].sum()\n",
    "        total_count = len(region_df)\n",
    "        \n",
    "        # Create a new row as a dictionary and append it to the DataFrame\n",
    "        new_row = {\n",
    "            'Model': model, \n",
    "            'AP': ap_count, \n",
    "            'BE': be_count, \n",
    "            'EP': ep_count, \n",
    "            'Count': total_count,\n",
    "            'AP:EP': ap_count / ep_count if ep_count != 0 else np.nan,\n",
    "            'AP_pct': ap_count / total_count * 100, \n",
    "            'BE_pct': be_count / total_count * 100, \n",
    "            'EP_pct': ep_count / total_count * 100\n",
    "        }\n",
    "        summary_df = pd.concat([summary_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    summary_tables[region] = summary_df\n",
    "\n",
    "# Create 1x2 grid figure with custom width ratios\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), gridspec_kw={'width_ratios': [1, 2]})\n",
    "\n",
    "# PLOT 1: Overall EP% (left panel)\n",
    "sns.barplot(\n",
    "    x='Model', \n",
    "    y='EP_pct', \n",
    "    data=summary_tables['overall'], \n",
    "    ax=axs[0], \n",
    "    palette=palette,\n",
    "    hue='Model',\n",
    "    legend=False\n",
    ")\n",
    "axs[0].set_title('Overall EP%', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[0].set_ylabel('EP%', fontsize=14)\n",
    "axs[0].set_xlabel('')  # Remove x-axis label\n",
    "axs[0].tick_params(axis='both', labelsize=14)\n",
    "axs[0].set_ylim(0, 50)  # Set y-axis range from 0 to 50\n",
    "axs[0].grid(False)  # Remove gridlines\n",
    "\n",
    "# Add data labels\n",
    "for p in axs[0].patches:\n",
    "    axs[0].annotate(f\"{p.get_height():.1f}%\", \n",
    "                  (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                  ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "# PLOT 2: EP% by Glycemic Region (right panel)\n",
    "# Create a new dataframe that combines the regional data for plotting\n",
    "regional_data = pd.concat([\n",
    "    summary_tables['hypo'][['Model', 'EP_pct']].assign(Region='Hypo'),\n",
    "    summary_tables['eu'][['Model', 'EP_pct']].assign(Region='Eu'),\n",
    "    summary_tables['hyper'][['Model', 'EP_pct']].assign(Region='Hyper')\n",
    "])\n",
    "\n",
    "sns.barplot(\n",
    "    x='Region', \n",
    "    y='EP_pct', \n",
    "    hue='Model',\n",
    "    data=regional_data, \n",
    "    ax=axs[1], \n",
    "    palette=palette\n",
    ")\n",
    "axs[1].set_title('EP% Across Glycemic Regions', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[1].set_ylabel('EP%', fontsize=14)\n",
    "axs[1].set_xlabel('Glycemic Region', fontsize=14)\n",
    "axs[1].tick_params(axis='both', labelsize=14)\n",
    "axs[1].set_ylim(0, 50)  # Set y-axis range from 0 to 50\n",
    "axs[1].grid(False)  # Remove gridlines\n",
    "\n",
    "# Add data labels to the second chart\n",
    "for container in axs[1].containers:\n",
    "    axs[1].bar_label(container, fmt='%.1f%%', fontsize=14)\n",
    "\n",
    "# Add legend to the right plot\n",
    "axs[1].legend(title='Model', fontsize=14, title_fontsize=14)\n",
    "\n",
    "# Remove top and right borders\n",
    "sns.despine(ax=axs[0])\n",
    "sns.despine(ax=axs[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # Adjust to make room for the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom colors for the models\n",
    "model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "palette = [model1_color, model2_color]\n",
    "\n",
    "# Create summary tables for overall, hypo, eu, and hyper glycaemic regions\n",
    "regions = ['overall', 'hypo', 'eu', 'hyper']\n",
    "summary_tables = {}\n",
    "\n",
    "for region in regions:\n",
    "    # Initialize empty DataFrame with specific dtypes to avoid warning\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Model': pd.Series(dtype='object'),\n",
    "        'AP': pd.Series(dtype='int64'), \n",
    "        'BE': pd.Series(dtype='int64'), \n",
    "        'EP': pd.Series(dtype='int64'), \n",
    "        'Count': pd.Series(dtype='int64'),\n",
    "        'AP_pct': pd.Series(dtype='float64'), \n",
    "        'BE_pct': pd.Series(dtype='float64'), \n",
    "        'EP_pct': pd.Series(dtype='float64')\n",
    "    })\n",
    "\n",
    "    \n",
    "    # Process each model\n",
    "    for model, df in zip(['base', 'fine-tuned'], \n",
    "                        [aggregate_base_df, aggregate_fine_tuned_df]):\n",
    "        \n",
    "        \n",
    "        # Filter for region if not overall\n",
    "        if region != 'overall':\n",
    "            region_df = df[df['glycemic_region'] == region]\n",
    "        else:\n",
    "            region_df = df\n",
    "            \n",
    "        # Calculate counts\n",
    "        ap_count = region_df['AP'].sum()\n",
    "        be_count = region_df['BE'].sum()\n",
    "        ep_count = region_df['EP'].sum()\n",
    "        total_count = len(region_df)\n",
    "        \n",
    "        # Create a new row as a dictionary and append it to the DataFrame\n",
    "        new_row = {\n",
    "            'Model': model, \n",
    "            'AP': ap_count, \n",
    "            'BE': be_count, \n",
    "            'EP': ep_count, \n",
    "            'Count': total_count,\n",
    "            'AP:EP': ap_count / ep_count if ep_count != 0 else np.nan,\n",
    "            'AP_pct': ap_count / total_count * 100, \n",
    "            'BE_pct': be_count / total_count * 100, \n",
    "            'EP_pct': ep_count / total_count * 100\n",
    "        }\n",
    "        summary_df = pd.concat([summary_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    summary_tables[region] = summary_df\n",
    "\n",
    "# Create 1x2 grid figure with custom width ratios\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), gridspec_kw={'width_ratios': [1, 2]})\n",
    "\n",
    "# PLOT 1: Overall AP% (left panel)\n",
    "sns.barplot(\n",
    "    x='Model', \n",
    "    y='AP_pct', \n",
    "    data=summary_tables['overall'], \n",
    "    ax=axs[0], \n",
    "    palette=palette,\n",
    "    hue='Model',\n",
    "    legend=False\n",
    ")\n",
    "axs[0].set_title('Overall AP%', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[0].set_ylabel('AP%', fontsize=14)\n",
    "axs[0].set_xlabel('')  # Remove x-axis label\n",
    "axs[0].tick_params(axis='both', labelsize=14)\n",
    "axs[0].set_ylim(50, 100)  # Set y-axis range from 0 to 100\n",
    "\n",
    "# Add data labels\n",
    "for p in axs[0].patches:\n",
    "    axs[0].annotate(f\"{p.get_height():.1f}%\", \n",
    "                  (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                  ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "# PLOT 2: AP% by Glycemic Region (right panel)\n",
    "# Create a new dataframe that combines the regional data for plotting\n",
    "regional_data = pd.concat([\n",
    "    summary_tables['hypo'][['Model', 'AP_pct']].assign(Region='Hypo'),\n",
    "    summary_tables['eu'][['Model', 'AP_pct']].assign(Region='Eu'),\n",
    "    summary_tables['hyper'][['Model', 'AP_pct']].assign(Region='Hyper')\n",
    "])\n",
    "\n",
    "sns.barplot(\n",
    "    x='Region', \n",
    "    y='AP_pct', \n",
    "    hue='Model',\n",
    "    data=regional_data, \n",
    "    ax=axs[1], \n",
    "    palette=palette,\n",
    "    legend=False\n",
    ")\n",
    "axs[1].set_title('AP% Across Glycemic Regions', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[1].set_ylabel('AP%', fontsize=14)\n",
    "axs[1].set_xlabel('Glycemic Region', fontsize=14)\n",
    "axs[1].tick_params(axis='both', labelsize=14)\n",
    "axs[1].set_ylim(50, 100)  # Set y-axis range from 0 to 100\n",
    "\n",
    "# Add data labels to the second chart\n",
    "for container in axs[1].containers:\n",
    "    axs[1].bar_label(container, fmt='%.1f%%', fontsize=14)\n",
    "\n",
    "# Add legend to the right plot\n",
    "\n",
    "\n",
    "# Remove top and right borders\n",
    "sns.despine(ax=axs[0])\n",
    "sns.despine(ax=axs[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # Adjust to make room for the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timepoint_ega_dataframe(df, region=None):\n",
    "    # Initialize a dataframe to store results with proper data types\n",
    "    result_df = pd.DataFrame(index=(np.arange(24)+1) * 5)  # timepoints (n+1) * 5\n",
    "    result_df.index.name = 'timepoint'\n",
    "    \n",
    "    # Initialize columns for percentages, counts and total\n",
    "    result_df['AP_percent'] = 0.0\n",
    "    result_df['BP_percent'] = 0.0\n",
    "    result_df['EP_percent'] = 0.0\n",
    "    result_df['AP_count'] = 0\n",
    "    result_df['BP_count'] = 0\n",
    "    result_df['EP_count'] = 0\n",
    "    result_df['Total_count'] = 0\n",
    "\n",
    "    \n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df = df.copy()\n",
    "\n",
    "    if region == 'hypo':\n",
    "        # Filter for hypoglycemic readings only\n",
    "        df = df[df['glycemic_region'] == 'hypo']\n",
    "    elif region == 'hyper':\n",
    "        # Filter for hyperglycemic readings only\n",
    "        df = df[df['glycemic_region'] == 'hyper']\n",
    "    elif region == 'eu':\n",
    "        # Filter for euglycemic readings only\n",
    "        df = df[df['glycemic_region'] == 'eu']\n",
    "    else:\n",
    "        df = df  # Use all data\n",
    "\n",
    "    # Process each timepoint\n",
    "    for timepoint in range(1,24):\n",
    "        # Filter data for this timepoint\n",
    "        timepoint_data = df[df['timepoint'] == timepoint]\n",
    "        \n",
    "        if len(timepoint_data) > 0:\n",
    "            # Count occurrences of each CG_EGA_Class\n",
    "            class_counts = timepoint_data['CG_EGA_Class'].value_counts()\n",
    "            total_points = len(timepoint_data)\n",
    "            \n",
    "            # Store total count for this timepoint\n",
    "            result_df.loc[(timepoint + 1) * 5, 'Total_count'] = total_points\n",
    "            \n",
    "            # Calculate percentages and counts for AP, BP, and EP\n",
    "            for class_prefix in ['A', 'B', 'E']:\n",
    "                # Find all classes that start with this letter (AP, BP, EP)\n",
    "                class_matches = [c for c in class_counts.index if c.startswith(class_prefix)]\n",
    "                count = sum([class_counts[c] for c in class_matches if c in class_counts])\n",
    "                \n",
    "                # Store count\n",
    "                result_df.loc[(timepoint + 1) * 5, f'{class_prefix}P_count'] = count\n",
    "                \n",
    "                # Store percentage\n",
    "                result_df.loc[(timepoint + 1) * 5, f'{class_prefix}P_percent'] = float((count / total_points) * 100)\n",
    "\n",
    "    result_df['AP:EP'] = result_df['AP_count'] / result_df['EP_count']\n",
    "\n",
    "\n",
    "    # result_df = result_df.drop(index=0)\n",
    "    # result_df = result_df.reset_index()\n",
    "    # result_df['timepoint'] = result_df['timepoint'].astype(int)\n",
    "\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ep_ph_chart(model1, model2, glycemic_region):\n",
    "    # Process data for each model using the create_timepoint_ega_dataframe function\n",
    "    model1_timepoint_table = create_timepoint_ega_dataframe(model1, glycemic_region)\n",
    "    model2_timepoint_table = create_timepoint_ega_dataframe(model2, glycemic_region)\n",
    "\n",
    "    # Plot the Erroneous Prediction % for both models\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "    model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "\n",
    "\n",
    "    plt.plot(model1_timepoint_table.index[1:], model1_timepoint_table['EP_percent'][1:], \n",
    "             label='Population JPFormer', marker='o', linestyle='-', markersize=4, \n",
    "             color=model1_color)\n",
    "    plt.plot(model2_timepoint_table.index[1:], model2_timepoint_table['EP_percent'][1:], \n",
    "             label='Personalised JPFormer', marker='o', linestyle='-', markersize=4, \n",
    "             color=model2_color)\n",
    "\n",
    "    # Add titles and labels\n",
    "\n",
    "    plt.title(f'EP%  by Prediction Horizon', \n",
    "              fontsize=16, fontweight='bold', ha='center', pad=20)\n",
    "    plt.xlabel('Prediction Horizon (mins)', fontsize=14, labelpad=5, ha='center')\n",
    "    plt.ylabel('EP Percent', fontsize=14, labelpad=5)\n",
    "    plt.xticks(range(0, 121, 30), fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # Format legend\n",
    "    legend = plt.legend(title='Model', fontsize=14, loc='upper center', bbox_to_anchor=(0.5, -0.2), \n",
    "                        ncol=2, frameon=False)\n",
    "\n",
    "    legend.get_title().set_fontsize(14)\n",
    "\n",
    "    # Add grid and styling\n",
    "    plt.grid(axis='y', linestyle='-', alpha=0.6)\n",
    "    plt.ylim(0, 50)  \n",
    "    sns.despine()  # Remove top and right borders\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the appropriate arguments'\n",
    "return_ep_ph_chart(model1=aggregate_base_df, model2=aggregate_fine_tuned_df, glycemic_region='overall')\n",
    "\n",
    "return_ep_ph_chart(model1=aggregate_base_df, model2=aggregate_fine_tuned_df, glycemic_region='hypo')\n",
    "\n",
    "return_ep_ph_chart(model1=aggregate_base_df, model2=aggregate_fine_tuned_df, glycemic_region='eu')\n",
    "\n",
    "return_ep_ph_chart(model1=aggregate_base_df, model2=aggregate_fine_tuned_df, glycemic_region='hyper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ap_ph_chart(model1, model2, glycemic_region):\n",
    "    # Process data for each model using the create_timepoint_ega_dataframe function\n",
    "    model1_timepoint_table = create_timepoint_ega_dataframe(model1, glycemic_region)\n",
    "    model2_timepoint_table = create_timepoint_ega_dataframe(model2, glycemic_region)\n",
    "\n",
    "    # Plot the Erroneous Prediction % for both models\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "    model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(model1_timepoint_table.index[1:], model1_timepoint_table['AP_percent'][1:], \n",
    "             label='Population JPFormer', marker='o', linestyle='-', markersize=4, \n",
    "             color=model1_color)\n",
    "    plt.plot(model2_timepoint_table.index[1:], model2_timepoint_table['AP_percent'][1:], \n",
    "             label='Personalised JPFormer', marker='o', linestyle='-', markersize=4, \n",
    "             color=model2_color)\n",
    "\n",
    "    # Add titles and labels\n",
    "\n",
    "    plt.title(f'AP%  by Prediction Horizon', \n",
    "              fontsize=16, fontweight='bold', ha='center', pad=20)\n",
    "    plt.xlabel('Prediction Horizon (mins)', fontsize=14, labelpad=5, ha='center')\n",
    "    plt.ylabel('AP Percent', fontsize=14, labelpad=5)\n",
    "    plt.xticks(range(0, 121, 30), fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # Format legend\n",
    "    legend = plt.legend(title='Model', fontsize=14, loc='upper center', bbox_to_anchor=(0.5, -0.2), \n",
    "                        ncol=2, frameon=False)\n",
    "\n",
    "    legend.get_title().set_fontsize(14)\n",
    "\n",
    "    # Add grid and styling\n",
    "    plt.grid(axis='y', linestyle='-', alpha=0.6)\n",
    "    plt.ylim(50, 100)  \n",
    "    sns.despine()  # Remove top and right borders\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the appropriate arguments'\n",
    "return_ap_ph_chart(model1=aggregate_base_df, model2=aggregate_fine_tuned_df, glycemic_region='overall')\n",
    "\n",
    "return_ap_ph_chart(model1=aggregate_base_df, model2=aggregate_fine_tuned_df, glycemic_region='hypo')\n",
    "\n",
    "return_ap_ph_chart(model1=aggregate_base_df, model2=aggregate_fine_tuned_df, glycemic_region='eu')\n",
    "\n",
    "return_ap_ph_chart(model1=aggregate_base_df, model2=aggregate_fine_tuned_df, glycemic_region='hyper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_timepoint_summary(no_fe_model, fe_model, glycemic_region):\n",
    "\n",
    "    timepoints = [30, 60, 90, 120]\n",
    "\n",
    "    # Create a dictionary to store DataFrames for each timepoint\n",
    "    timepoint_dfs = {}\n",
    "\n",
    "    # For each timepoint, create a DataFrame with rows from both models\n",
    "    for t in timepoints:\n",
    "        # Create an empty DataFrame\n",
    "        timepoint_df = pd.DataFrame(columns=['Model', 'AP_percent', 'BP_percent', 'EP_percent', \n",
    "                                            'AP_count', 'BP_count', 'EP_count', 'Total_count'])\n",
    "        \n",
    "            # Process data for each model using the create_timepoint_ega_dataframe function\n",
    "        model1_timepoint_table = create_timepoint_ega_dataframe(no_fe_model, glycemic_region)\n",
    "        model2_timepoint_table = create_timepoint_ega_dataframe(fe_model, glycemic_region)\n",
    "\n",
    "        # Get data from both models for this timepoint\n",
    "        no_fe_data = model1_timepoint_table.loc[t].copy()\n",
    "        fe_data = model2_timepoint_table.loc[t].copy()\n",
    "        \n",
    "        # Create rows with model identifiers\n",
    "        no_fe_row = pd.DataFrame({\n",
    "            'Model': ['Population JPFormer'],\n",
    "            'AP_percent': [no_fe_data['AP_percent']],\n",
    "            'BP_percent': [no_fe_data['BP_percent']],\n",
    "            'EP_percent': [no_fe_data['EP_percent']],\n",
    "            'AP_count': [no_fe_data['AP_count']],\n",
    "            'BP_count': [no_fe_data['BP_count']],\n",
    "            'EP_count': [no_fe_data['EP_count']],\n",
    "            'Total_count': [no_fe_data['Total_count']],\n",
    "            'AP:EP': [no_fe_data['AP:EP']]\n",
    "        })\n",
    "        \n",
    "        fe_row = pd.DataFrame({\n",
    "            'Model': ['Personalised JPFormer'],\n",
    "            'AP_percent': [fe_data['AP_percent']],\n",
    "            'BP_percent': [fe_data['BP_percent']],\n",
    "            'EP_percent': [fe_data['EP_percent']],\n",
    "            'AP_count': [fe_data['AP_count']],\n",
    "            'BP_count': [fe_data['BP_count']],\n",
    "            'EP_count': [fe_data['EP_count']],\n",
    "            'Total_count': [fe_data['Total_count']],\n",
    "            'AP:EP': [fe_data['AP:EP']]\n",
    "        })\n",
    "        \n",
    "        # Combine the two rows\n",
    "        timepoint_df = pd.concat([no_fe_row, fe_row])\n",
    "        \n",
    "        # Store in dictionary\n",
    "        timepoint_dfs[t] = timepoint_df\n",
    "\n",
    "    # Create a figure to visualize EP percentages across timepoints\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Define custom colors for the models\n",
    "    model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "    model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "    palette = [model1_color, model2_color]\n",
    "\n",
    "    # Plot bar charts for each timepoint\n",
    "    for i, t in enumerate(timepoints):\n",
    "        sns.barplot(\n",
    "            x='Model', \n",
    "            y='EP_percent', \n",
    "            data=timepoint_dfs[t], \n",
    "            ax=axs[i], \n",
    "            palette=palette,\n",
    "            hue='Model',\n",
    "            legend=False\n",
    "        )\n",
    "        axs[i].set_title(f'Prediction Horizon: {t} mins', fontsize=16, fontweight='bold', pad=20)\n",
    "        axs[i].set_ylabel('EP Precentage', fontsize=14)\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].set_ylim(0, 50)  # Set consistent y-axis limits\n",
    "        \n",
    "        # Add data labels\n",
    "        for p in axs[i].patches:\n",
    "            axs[i].annotate(f\"{p.get_height():.1f}%\", \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='bottom', fontsize=14)\n",
    "        \n",
    "        # Set x-tick labels font size to 8\n",
    "        axs[i].tick_params(axis='x', labelsize=12)\n",
    "        \n",
    "        # Remove top and right borders\n",
    "        sns.despine(ax=axs[i])\n",
    "    glycemic_region = glycemic_region.capitalize()\n",
    "\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85, hspace=0.4)  # Increased space between title and plots\n",
    "    plt.show()\n",
    "\n",
    "    # Display the comparison tables\n",
    "    for t in timepoints:\n",
    "        print(f\"\\nPrediction Horizon: {t} minutes\")\n",
    "        display(timepoint_dfs[t])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_timepoint_summary(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='overall')\n",
    "\n",
    "return_timepoint_summary(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='hypo')\n",
    "\n",
    "return_timepoint_summary(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='eu')\n",
    "\n",
    "return_timepoint_summary(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='hyper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ap_timepoint_summary(no_fe_model, fe_model, glycemic_region):\n",
    "\n",
    "    timepoints = [30, 60, 90, 120]\n",
    "\n",
    "    # Create a dictionary to store DataFrames for each timepoint\n",
    "    timepoint_dfs = {}\n",
    "\n",
    "    # For each timepoint, create a DataFrame with rows from both models\n",
    "    for t in timepoints:\n",
    "        # Create an empty DataFrame\n",
    "        timepoint_df = pd.DataFrame(columns=['Model', 'AP_percent', 'BP_percent', 'EP_percent', \n",
    "                                            'AP_count', 'BP_count', 'EP_count', 'Total_count'])\n",
    "        \n",
    "        # Process data for each model using the create_timepoint_ega_dataframe function\n",
    "        model1_timepoint_table = create_timepoint_ega_dataframe(no_fe_model, glycemic_region)\n",
    "        model2_timepoint_table = create_timepoint_ega_dataframe(fe_model, glycemic_region)\n",
    "\n",
    "        # Get data from both models for this timepoint\n",
    "        no_fe_data = model1_timepoint_table.loc[t].copy()\n",
    "        fe_data = model2_timepoint_table.loc[t].copy()\n",
    "        \n",
    "        # Create rows with model identifiers\n",
    "        no_fe_row = pd.DataFrame({\n",
    "            'Model': ['base model'],\n",
    "            'AP_percent': [no_fe_data['AP_percent']],\n",
    "            'BP_percent': [no_fe_data['BP_percent']],\n",
    "            'EP_percent': [no_fe_data['EP_percent']],\n",
    "            'AP_count': [no_fe_data['AP_count']],\n",
    "            'BP_count': [no_fe_data['BP_count']],\n",
    "            'EP_count': [no_fe_data['EP_count']],\n",
    "            'Total_count': [no_fe_data['Total_count']],\n",
    "            'AP:EP': [no_fe_data['AP:EP']]\n",
    "        })\n",
    "        \n",
    "        fe_row = pd.DataFrame({\n",
    "            'Model': ['fine-tuned models'],\n",
    "            'AP_percent': [fe_data['AP_percent']],\n",
    "            'BP_percent': [fe_data['BP_percent']],\n",
    "            'EP_percent': [fe_data['EP_percent']],\n",
    "            'AP_count': [fe_data['AP_count']],\n",
    "            'BP_count': [fe_data['BP_count']],\n",
    "            'EP_count': [fe_data['EP_count']],\n",
    "            'Total_count': [fe_data['Total_count']],\n",
    "            'AP:EP': [fe_data['AP:EP']]\n",
    "        })\n",
    "        \n",
    "        # Combine the two rows\n",
    "        timepoint_df = pd.concat([no_fe_row, fe_row])\n",
    "        \n",
    "        # Store in dictionary\n",
    "        timepoint_dfs[t] = timepoint_df\n",
    "\n",
    "    # Create a figure to visualize AP percentages across timepoints\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Define custom colors for the models\n",
    "    model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "    model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "    palette = [model1_color, model2_color]\n",
    "\n",
    "    # Plot bar charts for each timepoint\n",
    "    for i, t in enumerate(timepoints):\n",
    "        sns.barplot(\n",
    "            x='Model', \n",
    "            y='AP_percent',  # Changed from EP_percent to AP_percent\n",
    "            data=timepoint_dfs[t], \n",
    "            ax=axs[i], \n",
    "            palette=palette,\n",
    "            hue='Model',\n",
    "            legend=False\n",
    "        )\n",
    "        axs[i].set_title(f'Prediction Horizon: {t} mins', fontsize=16, fontweight='bold', pad=20)\n",
    "        axs[i].set_ylabel('AP Percentage', fontsize=14)  # Updated label\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].set_ylim(50, 100)  # Adjusted y-axis limits for AP percentages\n",
    "        \n",
    "        # Add data labels\n",
    "        for p in axs[i].patches:\n",
    "            axs[i].annotate(f\"{p.get_height():.1f}%\", \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='bottom', fontsize=14)\n",
    "        \n",
    "        # Set x-tick labels font size to 8\n",
    "        axs[i].tick_params(axis='x', labelsize=14)\n",
    "        \n",
    "        # Remove top and right borders\n",
    "        sns.despine(ax=axs[i])\n",
    "    glycemic_region = glycemic_region.capitalize()\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85, hspace=0.4)  # Increased space between title and plots\n",
    "    plt.show()\n",
    "\n",
    "    # Display the comparison tables\n",
    "    for t in timepoints:\n",
    "        print(f\"\\nPrediction Horizon: {t} minutes\")\n",
    "        display(timepoint_dfs[t])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_ap_timepoint_summary(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='overall')\n",
    "return_ap_timepoint_summary(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='hypo')\n",
    "return_ap_timepoint_summary(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='eu')\n",
    "return_ap_timepoint_summary(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='hyper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1. Statistical Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Function to compute Cram√©r's V\n",
    "def cramers_v(chi2, n, contingency_table):\n",
    "    \"\"\"Computes Cram√©r's V effect size from the chi-square test.\"\"\"\n",
    "    min_dim = min(np.shape(contingency_table)) - 1  # Min(row-1, col-1)\n",
    "    return np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else np.nan\n",
    "\n",
    "# Function to interpret Cram√©r's V effect size\n",
    "def interpret_cramers_v(v_value):\n",
    "    \"\"\"Provides qualitative interpretation of Cram√©r's V.\"\"\"\n",
    "    if pd.isna(v_value):  \n",
    "        return \"Not Enough Data\"\n",
    "    elif v_value < 0.1:\n",
    "        return \"Negligible Effect\"\n",
    "    elif v_value < 0.3:\n",
    "        return \"Small Effect\"\n",
    "    elif v_value < 0.5:\n",
    "        return \"Medium Effect\"\n",
    "    else:\n",
    "        return \"Large Effect\"\n",
    "\n",
    "# Chi-square analysis function\n",
    "def return_chi_square_analysis(no_fe_model, fe_model, glycemic_region, model1_name=\"Model w/o FE\", model2_name=\"Model w/ FE\"):\n",
    "    glycemic_region = glycemic_region.lower()\n",
    "    data_dist_chi_square_results = []\n",
    "\n",
    "    print(f\"\\n Running Chi-Square test for {model1_name} vs {model2_name} ({glycemic_region.capitalize()}glycaemic Range Performance):\\n\")\n",
    "\n",
    "    # Copy data to avoid modifying the originals\n",
    "    df1 = no_fe_model.copy()\n",
    "    df2 = fe_model.copy()\n",
    "\n",
    "    # Filter based on glycemic region\n",
    "    if glycemic_region == 'hypo':\n",
    "        df1 = df1[df1['glycemic_region'] == 'hypo']\n",
    "        df2 = df2[df2['glycemic_region'] == 'hypo']\n",
    "    elif glycemic_region == 'hyper':\n",
    "        df1 = df1[df1['glycemic_region'] == 'hyper']\n",
    "        df2 = df2[df2['glycemic_region'] == 'hyper']\n",
    "    elif glycemic_region == 'eu':\n",
    "        df1 = df1[df1['glycemic_region'] == 'eu']\n",
    "        df2 = df2[df2['glycemic_region'] == 'eu']\n",
    "    else:\n",
    "        pass  # Use all data\n",
    "\n",
    "    # Calculate class counts\n",
    "    df1_counts = df1['CG_EGA_Class'].value_counts()\n",
    "    df2_counts = df2['CG_EGA_Class'].value_counts()\n",
    "    \n",
    "    # Totals\n",
    "    df1_total = df1_counts.sum()\n",
    "    df2_total = df2_counts.sum()\n",
    "\n",
    "    # Contingency table\n",
    "    contingency_table = [\n",
    "        [df1_counts.get('AP', 0), df1_counts.get('BE', 0), df1_counts.get('EP', 0)],\n",
    "        [df2_counts.get('AP', 0), df2_counts.get('BE', 0), df2_counts.get('EP', 0)],\n",
    "    ]\n",
    "\n",
    "    # Percentages\n",
    "    df1_percent = {\n",
    "        'AP': (df1_counts.get('AP', 0) / df1_total) * 100 if df1_total else 0,\n",
    "        'BE': (df1_counts.get('BE', 0) / df1_total) * 100 if df1_total else 0,\n",
    "        'EP': (df1_counts.get('EP', 0) / df1_total) * 100 if df1_total else 0\n",
    "    }\n",
    "    df2_percent = {\n",
    "        'AP': (df2_counts.get('AP', 0) / df2_total) * 100 if df2_total else 0,\n",
    "        'BE': (df2_counts.get('BE', 0) / df2_total) * 100 if df2_total else 0,\n",
    "        'EP': (df2_counts.get('EP', 0) / df2_total) * 100 if df2_total else 0\n",
    "    }\n",
    "\n",
    "    # Chi-square test\n",
    "    chi2, p_value, _, _ = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "    # Cram√©r's V\n",
    "    n = np.sum(contingency_table)\n",
    "    cramers_v_value = cramers_v(chi2, n, contingency_table)\n",
    "    cramers_v_interpretation = interpret_cramers_v(cramers_v_value)\n",
    "\n",
    "    # Store result\n",
    "    data_dist_chi_square_results.append({\n",
    "        \"Model 1\": f\"{model1_name} ({glycemic_region.capitalize()})\",\n",
    "        \"Model 2\": f\"{model2_name} ({glycemic_region.capitalize()})\",\n",
    "        \"Chi2 Statistic\": chi2,\n",
    "        \"p-value\": p_value,\n",
    "        \"Significant\": p_value < 0.05,\n",
    "        \"Cram√©r's V\": cramers_v_value,\n",
    "        \"Cram√©r's V Interpretation\": cramers_v_interpretation\n",
    "    })\n",
    "\n",
    "    # Display results\n",
    "    print(f\"\\n  œá¬≤ = {chi2:.3f}, p = {p_value:.5f}, \"\n",
    "          f\"{'Significant' if p_value < 0.05 else 'Not Significant'} | \"\n",
    "          f\"Cram√©r's V = {cramers_v_value:.3f} ({cramers_v_interpretation})\\n\")\n",
    "\n",
    "    # Contingency table (readable)\n",
    "    table_data = pd.DataFrame({\n",
    "        \"AP (Accurate Predictions)\": [f\"{df1_counts.get('AP', 0)} ({df1_percent['AP']:.2f}%)\", \n",
    "                                     f\"{df2_counts.get('AP', 0)} ({df2_percent['AP']:.2f}%)\"],\n",
    "        \"BE (Benign Errors)\": [f\"{df1_counts.get('BE', 0)} ({df1_percent['BE']:.2f}%)\", \n",
    "                              f\"{df2_counts.get('BE', 0)} ({df2_percent['BE']:.2f}%)\"],\n",
    "        \"EP (Erroneous Predictions)\": [f\"{df1_counts.get('EP', 0)} ({df1_percent['EP']:.2f}%)\", \n",
    "                                      f\"{df2_counts.get('EP', 0)} ({df2_percent['EP']:.2f}%)\"]\n",
    "    }, index=[model1_name, model2_name])\n",
    "\n",
    "    print(\"\\nContingency Table:\")\n",
    "    display(table_data)\n",
    "\n",
    "    return pd.DataFrame(data_dist_chi_square_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chi_square_results = return_chi_square_analysis(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='overall', model1_name=\"Base model\", model2_name=\"Fine-tuned models\")\n",
    "hypo_chi_square_results = return_chi_square_analysis(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='hypo', model1_name=\"Base model\", model2_name=\"Fine-tuned models\")\n",
    "eu_chi_square_results = return_chi_square_analysis(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='eu', model1_name=\"Base model\", model2_name=\"Fine-tuned models\")\n",
    "hyper_chi_square_results = return_chi_square_analysis(aggregate_base_df, aggregate_fine_tuned_df, glycemic_region='hyper', model1_name=\"Base model\", model2_name=\"Fine-tuned models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rows for specific prediction horizons (timepoints)\n",
    "population_30_df = aggregate_base_df[aggregate_base_df['timepoint'] == 5]\n",
    "population_60_df = aggregate_base_df[aggregate_base_df['timepoint'] == 11]\n",
    "population_90_df = aggregate_base_df[aggregate_base_df['timepoint'] == 17]\n",
    "population_120_df = aggregate_base_df[aggregate_base_df['timepoint'] == 23]\n",
    "\n",
    "# Do the same for the fine-tuned model\n",
    "personalized_30_df = aggregate_fine_tuned_df[aggregate_fine_tuned_df['timepoint'] == 5]\n",
    "personalized_60_df = aggregate_fine_tuned_df[aggregate_fine_tuned_df['timepoint'] == 11]\n",
    "personalized_90_df = aggregate_fine_tuned_df[aggregate_fine_tuned_df['timepoint'] == 17]\n",
    "personalized_120_df = aggregate_fine_tuned_df[aggregate_fine_tuned_df['timepoint'] == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_chi_square_analysis(population_30_df, personalized_30_df, glycemic_region='hypo', model1_name=\"Population JPFormer 30\", model2_name=\"Personalised JPFormer 30\")\n",
    "return_chi_square_analysis(population_60_df, personalized_60_df, glycemic_region='hypo', model1_name=\"Population JPFormer 60\", model2_name=\"Personalised JPFormer 60\")\n",
    "return_chi_square_analysis(population_90_df, personalized_90_df, glycemic_region='hypo', model1_name=\"Population JPFormer 90\", model2_name=\"Personalised JPFormer 90\")\n",
    "return_chi_square_analysis(population_120_df, personalized_120_df, glycemic_region='hypo', model1_name=\"Population JPFormer 120\", model2_name=\"Personalised JPFormer 120\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Individual Level Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE and MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptid_base_rmse_dict = {}\n",
    "\n",
    "ptid_fine_tuned_rmse_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "for ptid, df in base_overall_dict.items():\n",
    "    base_rmse = calculate_rmse(df['true_glucose'], df['predicted_glucose'])\n",
    "    ptid_base_rmse_dict[ptid] = base_rmse\n",
    "\n",
    "for ptid, df in fine_tuned_dict.items():\n",
    "    fine_tuned_rmse = calculate_rmse(df['true_glucose'], df['predicted_glucose'])\n",
    "    ptid_fine_tuned_rmse_dict[ptid] = fine_tuned_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with a 3x4 grid layout\n",
    "fig, axs = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axs = axs.flatten()  # Convert to 1D array for easier indexing\n",
    "\n",
    "# Define custom colors for the models\n",
    "model1_color = (173 / 255, 29 / 255, 30 / 255)  # Base model\n",
    "model2_color = (110 / 255, 180 / 255, 186 / 255)  # Fine-tuned model\n",
    "palette = [model1_color, model2_color]\n",
    "\n",
    "# Loop through each patient ID and create a bar chart in each subplot\n",
    "for i, ptid in enumerate(ptid_list):\n",
    "    # Create a DataFrame for this patient's RMSE values\n",
    "    df = pd.DataFrame({\n",
    "        'Model': ['Base Model', 'Fine-Tuned Model'],\n",
    "        'RMSE': [ptid_base_rmse_dict[ptid], ptid_fine_tuned_rmse_dict[ptid]]\n",
    "    })\n",
    "    \n",
    "    # Create bar chart in the corresponding subplot\n",
    "    sns.barplot(x='Model', y='RMSE', data=df, ax=axs[i], palette=palette)\n",
    "    \n",
    "    # Set title and styling for the subplot\n",
    "    axs[i].set_title(f'Patient {ptid}', fontsize=12, fontweight='bold')\n",
    "    axs[i].set_ylabel('RMSE (mg/dL)', fontsize=10)\n",
    "    axs[i].set_xlabel('')\n",
    "    \n",
    "    # Add data labels\n",
    "    for p in axs[i].patches:\n",
    "        axs[i].annotate(f\"{p.get_height():.1f}\", \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                      ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Remove top and right borders\n",
    "    sns.despine(ax=axs[i])\n",
    "    \n",
    "    # Set y-axis limits based on the data range\n",
    "    max_value = max(ptid_base_rmse_dict[ptid], ptid_fine_tuned_rmse_dict[ptid])\n",
    "    axs[i].set_ylim(0, 50)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.suptitle('RMSE Comparison by Person ID: Base Model vs Fine-Tuned Model', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptid_base_mape_dict = {}\n",
    "ptid_fine_tuned_mape_dict = {}\n",
    "\n",
    "for ptid, df in base_overall_dict.items():\n",
    "    base_mape = mape(df['true_glucose'], df['predicted_glucose'])\n",
    "    ptid_base_mape_dict[ptid] = base_mape\n",
    "\n",
    "for ptid, df in fine_tuned_dict.items():\n",
    "    fine_tuned_mape = mape(df['true_glucose'], df['predicted_glucose'])\n",
    "    ptid_fine_tuned_mape_dict[ptid] = fine_tuned_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a figure with a 3x4 grid layout\n",
    "fig, axs = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axs = axs.flatten()  # Convert to 1D array for easier indexing\n",
    "\n",
    "# Define custom colors for the models\n",
    "model1_color = (173 / 255, 29 / 255, 30 / 255)  # Base model\n",
    "model2_color = (110 / 255, 180 / 255, 186 / 255)  # Fine-tuned model\n",
    "palette = [model1_color, model2_color]\n",
    "\n",
    "# Loop through each patient ID and create a bar chart in each subplot\n",
    "for i, ptid in enumerate(ptid_list):\n",
    "    # Create a DataFrame for this patient's RMSE values\n",
    "    df = pd.DataFrame({\n",
    "        'Model': ['Base Model', 'Fine-Tuned Model'],\n",
    "        'MAPE': [ptid_base_mape_dict[ptid], ptid_fine_tuned_mape_dict[ptid]]\n",
    "    })\n",
    "    \n",
    "    # Create bar chart in the corresponding subplot\n",
    "    sns.barplot(x='Model', y='MAPE', data=df, ax=axs[i], palette=palette)\n",
    "    \n",
    "    # Set title and styling for the subplot\n",
    "    axs[i].set_title(f'Patient {ptid}', fontsize=12, fontweight='bold')\n",
    "    axs[i].set_ylabel('RMSE (mg/dL)', fontsize=10)\n",
    "    axs[i].set_xlabel('')\n",
    "    \n",
    "    # Add data labels\n",
    "    for p in axs[i].patches:\n",
    "        axs[i].annotate(f\"{p.get_height():.1f}\", \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                      ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Remove top and right borders\n",
    "    sns.despine(ax=axs[i])\n",
    "    \n",
    "    axs[i].set_ylim(0, 50)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.suptitle('MAPE Comparison by Person ID: Base Model vs Fine-Tuned Model', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_results_dict = {}\n",
    "for ptid in ptid_list:\n",
    "    ttest_results = return_ttests(base_overall_dict[ptid], fine_tuned_dict[ptid], glycemic_region=\"overall\", model1_name=\"Base Model\", model2_name=\"Fine-tuned Model\")\n",
    "    ttest_results_dict[ptid] = ttest_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single dataframe to store all t-test results\n",
    "ttest_results_rmse_df = pd.DataFrame(columns=[\"Patient ID\", \"Base RMSE\", \"Fine-tuned RMSE\", \"t-statistic\", \"p-value\", \"Significant\"])\n",
    "for ptid, results in ttest_results_dict.items():\n",
    "    # Extract RMSE row from the t-test results\n",
    "    rmse_row = results.loc[0]\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Patient ID\": [ptid],\n",
    "        \"Base RMSE\": [ptid_base_rmse_dict[ptid]],\n",
    "        \"Fine-tuned RMSE\": [ptid_fine_tuned_rmse_dict[ptid]],\n",
    "        \"t-statistic\": [rmse_row[\"t-statistic\"]],\n",
    "        \"p-value\": [rmse_row[\"p-value\"]],\n",
    "        \"Significant\": [rmse_row[\"p-value\"] < 0.05]\n",
    "    })\n",
    "    ttest_results_rmse_df = pd.concat([ttest_results_rmse_df, new_row], ignore_index=True)\n",
    "\n",
    "# Format RMSE values to 2 decimal places\n",
    "ttest_results_rmse_df[\"Base RMSE\"] = ttest_results_rmse_df[\"Base RMSE\"].round(2)\n",
    "ttest_results_rmse_df[\"Fine-tuned RMSE\"] = ttest_results_rmse_df[\"Fine-tuned RMSE\"].round(2)\n",
    "ttest_results_rmse_df[\"t-statistic\"] = ttest_results_rmse_df[\"t-statistic\"].round(3)\n",
    "ttest_results_rmse_df[\"p-value\"] = ttest_results_rmse_df[\"p-value\"].map(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "ttest_results_rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_results_mape_df = pd.DataFrame(columns=[\"Patient ID\", \"Base MAPE\", \"Fine-tuned MAPE\", \"t-statistic\", \"p-value\", \"Significant\"])\n",
    "for ptid, results in ttest_results_dict.items():\n",
    "    # Extract MAPE row from the t-test results\n",
    "    mape_row = results.loc[1]\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Patient ID\": [ptid],\n",
    "        \"Base MAPE\": [ptid_base_mape_dict[ptid]],\n",
    "        \"Fine-tuned MAPE\": [ptid_fine_tuned_mape_dict[ptid]],\n",
    "        \"t-statistic\": [mape_row[\"t-statistic\"]],\n",
    "        \"p-value\": [mape_row[\"p-value\"]],\n",
    "        \"Significant\": [mape_row[\"p-value\"] < 0.05]\n",
    "    })\n",
    "    ttest_results_mape_df = pd.concat([ttest_results_mape_df, new_row], ignore_index=True)\n",
    "\n",
    "# Format MAPE values to 2 decimal places\n",
    "ttest_results_mape_df[\"Base MAPE\"] = ttest_results_mape_df[\"Base MAPE\"].round(2)\n",
    "ttest_results_mape_df[\"Fine-tuned MAPE\"] = ttest_results_mape_df[\"Fine-tuned MAPE\"].round(2)\n",
    "ttest_results_mape_df[\"t-statistic\"] = ttest_results_mape_df[\"t-statistic\"].round(3)\n",
    "ttest_results_mape_df[\"p-value\"] = ttest_results_mape_df[\"p-value\"].map(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "ttest_results_mape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a 1x2 grid layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "# RMSE Difference Chart\n",
    "df_rmse_diff = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in ptid_rmse_diff.keys()],\n",
    "    'RMSE Difference': [-diff for diff in ptid_rmse_diff.values()]  # Negate to make positive = base better\n",
    "})\n",
    "df_rmse_diff = df_rmse_diff.sort_values('RMSE Difference')\n",
    "colors_rmse = ['#AEB4B8'] * len(df_rmse_diff)\n",
    "for i, val in enumerate(df_rmse_diff['RMSE Difference']):\n",
    "    colors_rmse[i] = model2_color if val > 0 else model1_color\n",
    "bars_rmse = axs[0].barh(df_rmse_diff['Patient ID'], df_rmse_diff['RMSE Difference'], color=colors_rmse)\n",
    "axs[0].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "axs[0].set_xlabel('RMSE (mg/dL)', fontsize=14)\n",
    "axs[0].set_xlim(-6, 6)\n",
    "# Add data labels with asterisks for significant values\n",
    "for i, bar in enumerate(bars_rmse):\n",
    "    width = bar.get_width()\n",
    "    label_x_pos = width + 0.1 if width > 0 else width - 0.1\n",
    "    \n",
    "    # Get the patient ID number\n",
    "    ptid = int(df_rmse_diff.iloc[i]['Patient ID'].split(' ')[1])\n",
    "    \n",
    "    # Check if this patient has a significant p-value\n",
    "    is_significant = ttest_results_rmse_df.loc[ttest_results_rmse_df['Patient ID'] == ptid, 'Significant'].values[0]\n",
    "    \n",
    "    # Add an asterisk if significant\n",
    "    suffix = \"*\" if is_significant == True else \"\"\n",
    "    \n",
    "    axs[0].text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{abs(width):.2f}{suffix}',\n",
    "                va='center', ha='left' if width > 0 else 'right', fontsize=12)\n",
    "sns.despine(ax=axs[0])\n",
    "\n",
    "# MAPE Difference Chart\n",
    "df_mape_diff = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in ptid_mape_diff.keys()],\n",
    "    'MAPE Difference': [-diff for diff in ptid_mape_diff.values()]  # Negate to make positive = base better\n",
    "})\n",
    "df_mape_diff = df_mape_diff.sort_values('MAPE Difference')\n",
    "colors_mape = ['#AEB4B8'] * len(df_mape_diff)\n",
    "for i, val in enumerate(df_mape_diff['MAPE Difference']):\n",
    "    colors_mape[i] = model2_color if val > 0 else model1_color\n",
    "bars_mape = axs[1].barh(df_mape_diff['Patient ID'], df_mape_diff['MAPE Difference'], color=colors_mape)\n",
    "axs[1].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "axs[1].set_xlabel('MAPE ', fontsize=14)\n",
    "axs[1].set_xlim(-6, 6)\n",
    "# Add data labels with asterisks for significant values\n",
    "for i, bar in enumerate(bars_mape):\n",
    "    width = bar.get_width()\n",
    "    label_x_pos = width + 0.1 if width > 0 else width - 0.1\n",
    "    \n",
    "    # Get the patient ID number\n",
    "    ptid = int(df_mape_diff.iloc[i]['Patient ID'].split(' ')[1])\n",
    "    \n",
    "    # Get p-value and check if it's significant\n",
    "    p_value = float(ttest_results_mape_df.loc[ttest_results_mape_df['Patient ID'] == ptid, 'p-value'])\n",
    "    is_significant = p_value < 0.05\n",
    "    \n",
    "    # Add an asterisk if significant\n",
    "    suffix = \"*\" if is_significant else \"\"\n",
    "    \n",
    "    axs[1].text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{abs(width):.2f}{suffix}',\n",
    "                va='center', ha='left' if width > 0 else 'right', fontsize=12)\n",
    "sns.despine(ax=axs[1])\n",
    "\n",
    "for ax in axs:\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.text(xlim[0]+0.25, ylim[0] - 0.8, 'Population model\\n better', \n",
    "            color=model1_color, fontsize=12, fontweight='bold', ha='left', va='top')\n",
    "    ax.text(xlim[1]-0.25, ylim[0] - 0.8, 'Personalised model\\n better', \n",
    "            color=model2_color, fontsize=12, fontweight='bold', ha='right', va='top')\n",
    "\n",
    "plt.suptitle('Overall RMSE and MAPE Difference: Population vs Personalised JPFormer',\n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "# # Add a note explaining the asterisk\n",
    "# fig.text(0.5, 0.01, '* indicates statistically significant difference (p < 0.05)',\n",
    "#          ha='center', fontsize=12, fontstyle='italic')\n",
    "# plt.subplots_adjust(top=0.95, bottom=0.05)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CG-EGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_base_df = {}\n",
    "updated_fine_tuned_df = {}\n",
    "\n",
    "\n",
    "for ptid in ptid_list:\n",
    "    base_df = base_overall_dict[ptid]\n",
    "\n",
    "    base_df['AP'] = np.where(base_df['CG_EGA_Class'] == 'AP', 1, 0)\n",
    "    base_df['BE'] = np.where(base_df['CG_EGA_Class'] == 'BE', 1, 0)\n",
    "    base_df['EP'] = np.where(base_df['CG_EGA_Class'] == 'EP', 1, 0)\n",
    "    \n",
    "    updated_base_df[ptid] = base_df\n",
    "\n",
    "\n",
    "    fine_tuned_df = fine_tuned_dict[ptid]\n",
    "    fine_tuned_df['AP'] = np.where(fine_tuned_df['CG_EGA_Class'] == 'AP', 1, 0)\n",
    "    fine_tuned_df['BE'] = np.where(fine_tuned_df['CG_EGA_Class'] == 'BE', 1, 0)\n",
    "    fine_tuned_df['EP'] = np.where(fine_tuned_df['CG_EGA_Class'] == 'EP', 1, 0)\n",
    "    \n",
    "    updated_fine_tuned_df[ptid] = fine_tuned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run chi2 test for each patient id for overall model performacne\n",
    "\n",
    "overall_chi2_results_dict = {}\n",
    "hypo_chi2_results_dict  = {}\n",
    "eu_chi2_results_dict  = {}\n",
    "hyper_chi2_results_dict  = {}\n",
    "\n",
    "for ptid in ptid_list:\n",
    "\n",
    "    overall_chi2_results_dict[ptid] = return_chi_square_analysis(updated_base_df[ptid], updated_fine_tuned_df[ptid], glycemic_region='overall', model1_name='Population JPFormer', model2_name='Personalised JPFormer')\n",
    "    \n",
    "\n",
    "    hypo_chi2_results_dict[ptid] = return_chi_square_analysis(updated_base_df[ptid], updated_fine_tuned_df[ptid], glycemic_region='hypo', model1_name='Population JPFormer', model2_name='Personalised JPFormer')\n",
    "\n",
    "\n",
    "    eu_chi2_results_dict[ptid] = return_chi_square_analysis(updated_base_df[ptid], updated_fine_tuned_df[ptid], glycemic_region='eu', model1_name='Population JPFormer', model2_name='Personalised JPFormer')\n",
    "\n",
    "\n",
    "    hyper_chi2_results_dict[ptid] = return_chi_square_analysis(updated_base_df[ptid], updated_fine_tuned_df[ptid], glycemic_region='hyper', model1_name='Population JPFormer', model2_name='Personalised JPFormer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframes for each glycemic region\n",
    "overall_chi2_summary = pd.DataFrame(columns=[\"Patient ID\", \"Chi2\", \"p-value\", \"Significant\"])\n",
    "hypo_chi2_summary = pd.DataFrame(columns=[\"Patient ID\", \"Chi2\", \"p-value\",  \"Significant\"])\n",
    "eu_chi2_summary = pd.DataFrame(columns=[\"Patient ID\", \"Chi2\", \"p-value\", \"Significant\"])\n",
    "hyper_chi2_summary = pd.DataFrame(columns=[\"Patient ID\", \"Chi2\", \"p-value\", \"Significant\"])\n",
    "\n",
    "# Populate the dataframes with results from each patient\n",
    "for ptid in ptid_list:\n",
    "    # Overall results\n",
    "    overall_row = pd.DataFrame({\n",
    "        \"Patient ID\": [ptid],\n",
    "        \"Chi2\": [overall_chi2_results_dict[ptid][\"Chi2 Statistic\"].iloc[0]],\n",
    "        \"p-value\": [overall_chi2_results_dict[ptid][\"p-value\"].iloc[0]],\n",
    "        \"Significant\": [overall_chi2_results_dict[ptid][\"p-value\"].iloc[0] < 0.05]\n",
    "\n",
    "    })\n",
    "    overall_chi2_summary = pd.concat([overall_chi2_summary, overall_row], ignore_index=True)\n",
    "    \n",
    "    # Hypo results\n",
    "    hypo_row = pd.DataFrame({\n",
    "        \"Patient ID\": [ptid],\n",
    "        \"Chi2\": [hypo_chi2_results_dict[ptid][\"Chi2 Statistic\"].iloc[0]],\n",
    "        \"p-value\": [hypo_chi2_results_dict[ptid][\"p-value\"].iloc[0]],\n",
    "        \"Significant\": [hypo_chi2_results_dict[ptid][\"p-value\"].iloc[0] < 0.05]\n",
    "\n",
    "    })\n",
    "    hypo_chi2_summary = pd.concat([hypo_chi2_summary, hypo_row], ignore_index=True)\n",
    "    \n",
    "    # Eu results\n",
    "    eu_row = pd.DataFrame({\n",
    "        \"Patient ID\": [ptid],\n",
    "        \"Chi2\": [eu_chi2_results_dict[ptid][\"Chi2 Statistic\"].iloc[0]],\n",
    "        \"p-value\": [eu_chi2_results_dict[ptid][\"p-value\"].iloc[0]],\n",
    "        \"Significant\": [eu_chi2_results_dict[ptid][\"p-value\"].iloc[0] < 0.05]\n",
    "\n",
    "    })\n",
    "    eu_chi2_summary = pd.concat([eu_chi2_summary, eu_row], ignore_index=True)\n",
    "    \n",
    "    # Hyper results\n",
    "    hyper_row = pd.DataFrame({\n",
    "        \"Patient ID\": [ptid],\n",
    "        \"Chi2\": [hyper_chi2_results_dict[ptid][\"Chi2 Statistic\"].iloc[0]],\n",
    "        \"p-value\": [hyper_chi2_results_dict[ptid][\"p-value\"].iloc[0]],\n",
    "        \"Significant\": [hyper_chi2_results_dict[ptid][\"p-value\"].iloc[0] < 0.05]\n",
    "\n",
    "    })\n",
    "    hyper_chi2_summary = pd.concat([hyper_chi2_summary, hyper_row], ignore_index=True)\n",
    "\n",
    "# Format the dataframes\n",
    "for df in [overall_chi2_summary, hypo_chi2_summary, eu_chi2_summary, hyper_chi2_summary]:\n",
    "    df[\"Chi2\"] = df[\"Chi2\"].round(3)\n",
    "    df[\"p-value\"] = df[\"p-value\"].map(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "    df[\"Patient ID\"] = df[\"Patient ID\"].astype(int)\n",
    "\n",
    "# Display the summaries\n",
    "print(\"Overall Chi-Square Test Results:\")\n",
    "display(overall_chi2_summary)\n",
    "\n",
    "print(\"\\nHypoglycemia Chi-Square Test Results:\")\n",
    "display(hypo_chi2_summary)\n",
    "\n",
    "print(\"\\nEuglycemia Chi-Square Test Results:\")\n",
    "display(eu_chi2_summary)\n",
    "\n",
    "print(\"\\nHyperglycemia Chi-Square Test Results:\")\n",
    "display(hyper_chi2_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ptid in ptid_list:\n",
    "    print(f\"Patient ID: {ptid}\")\n",
    "\n",
    "    # Define custom colors for the models\n",
    "    model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "    model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "    palette = [model1_color, model2_color]\n",
    "\n",
    "    # Create summary tables for overall, hypo, eu, and hyper glycaemic regions\n",
    "    regions = ['overall', 'hypo', 'eu', 'hyper']\n",
    "    summary_tables = {}\n",
    "\n",
    "    # Get the dataframes for the current patient ID\n",
    "    base_df = updated_base_df[ptid]\n",
    "    fine_tuned_df = updated_fine_tuned_df[ptid]\n",
    "    \n",
    "    for region in regions:\n",
    "        # Initialize empty DataFrame with specific dtypes to avoid warning\n",
    "        summary_df = pd.DataFrame({\n",
    "            'Model': pd.Series(dtype='object'),\n",
    "            'AP': pd.Series(dtype='int64'), \n",
    "            'BE': pd.Series(dtype='int64'), \n",
    "            'EP': pd.Series(dtype='int64'), \n",
    "            'Count': pd.Series(dtype='int64'),\n",
    "            'AP_pct': pd.Series(dtype='float64'), \n",
    "            'BE_pct': pd.Series(dtype='float64'), \n",
    "            'EP_pct': pd.Series(dtype='float64')\n",
    "        })\n",
    "        \n",
    "        # Process each model\n",
    "        for model, df in zip(['base model', 'fine-tuned models'], \n",
    "                            [base_df, fine_tuned_df]):\n",
    "            \n",
    "            # Filter for region if not overall\n",
    "            if region != 'overall':\n",
    "                region_df = df[df['glycemic_region'] == region]\n",
    "            else:\n",
    "                region_df = df\n",
    "                \n",
    "            # Calculate counts\n",
    "            ap_count = region_df['AP'].sum()\n",
    "            be_count = region_df['BE'].sum()\n",
    "            ep_count = region_df['EP'].sum()\n",
    "            total_count = len(region_df)\n",
    "            \n",
    "            # Create a new row as a dictionary and append it to the DataFrame\n",
    "            new_row = {\n",
    "                'Model': model, \n",
    "                'AP': ap_count, \n",
    "                'BE': be_count, \n",
    "                'EP': ep_count, \n",
    "                'Count': total_count,\n",
    "                'AP:EP': ap_count / ep_count if ep_count != 0 else np.nan,\n",
    "                'AP_pct': ap_count / total_count * 100, \n",
    "                'BE_pct': be_count / total_count * 100, \n",
    "                'EP_pct': ep_count / total_count * 100\n",
    "            }\n",
    "            summary_df = pd.concat([summary_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "        # Store in dictionary\n",
    "        summary_tables[region] = summary_df\n",
    "\n",
    "    # Create 1x2 grid figure with custom width ratios\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={'width_ratios': [1, 2]})\n",
    "\n",
    "    # PLOT 1: Overall EP percentage (left panel)\n",
    "    sns.barplot(\n",
    "        x='Model', \n",
    "        y='EP_pct', \n",
    "        data=summary_tables['overall'], \n",
    "        ax=axs[0], \n",
    "        palette=palette,\n",
    "        hue='Model',\n",
    "        legend=False\n",
    "    )\n",
    "    axs[0].set_title(f'Overall Error Percentage (Patient {ptid})', fontsize=14, fontweight='bold')\n",
    "    axs[0].set_ylabel('Error Percentage (%)', fontsize=12)\n",
    "    axs[0].set_xlabel('')  # Remove x-axis label\n",
    "    axs[0].tick_params(axis='both', labelsize=9)\n",
    "    axs[0].set_ylim(0, 50)  # Adjusted y-axis range for percentage values\n",
    "\n",
    "    # Add data labels\n",
    "    for p in axs[0].patches:\n",
    "        axs[0].annotate(f\"{p.get_height():.1f}%\", \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "    # PLOT 2: EP percentage by Glycemic Region (right panel)\n",
    "    # Create a new dataframe that combines the regional data for plotting\n",
    "    regional_data = pd.concat([\n",
    "        summary_tables['hypo'][['Model', 'EP_pct']].assign(Region='Hypo'),\n",
    "        summary_tables['eu'][['Model', 'EP_pct']].assign(Region='Eu'),\n",
    "        summary_tables['hyper'][['Model', 'EP_pct']].assign(Region='Hyper')\n",
    "    ])\n",
    "\n",
    "    sns.barplot(\n",
    "        x='Region', \n",
    "        y='EP_pct', \n",
    "        hue='Model',\n",
    "        data=regional_data, \n",
    "        ax=axs[1], \n",
    "        palette=palette\n",
    "    )\n",
    "    axs[1].set_title(f'Error Percentage Across Glycemic Regions (Patient {ptid})', fontsize=14, fontweight='bold')\n",
    "    axs[1].set_ylabel('Error Percentage (%)', fontsize=12)\n",
    "    axs[1].set_xlabel('Glycemic Region', fontsize=12)\n",
    "    axs[1].tick_params(axis='both', labelsize=10)\n",
    "    axs[1].set_ylim(0,50)  # Adjusted y-axis range for percentage values\n",
    "\n",
    "    # Add data labels to the second chart\n",
    "    for container in axs[1].containers:\n",
    "        axs[1].bar_label(container, fmt='%.1f%%', fontsize=11, fontweight='bold')\n",
    "\n",
    "    # Add legend to the right plot\n",
    "    axs[1].legend(title='Model', fontsize=9, title_fontsize=10)\n",
    "\n",
    "    # Remove top and right borders\n",
    "    sns.despine(ax=axs[0])\n",
    "    sns.despine(ax=axs[1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)  # Adjust to make room for the title\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ptid in ptid_list:\n",
    "    print(f\"Patient ID: {ptid}\")\n",
    "\n",
    "    # Define custom colors for the models\n",
    "    model1_color = (173 / 255, 29 / 255, 30 / 255)  # Without Feature Enhancement\n",
    "    model2_color = (110 / 255, 180 / 255, 186 / 255)  # With Feature Enhancement\n",
    "    palette = [model1_color, model2_color]\n",
    "\n",
    "    # Create summary tables for overall, hypo, eu, and hyper glycaemic regions\n",
    "    regions = ['overall', 'hypo', 'eu', 'hyper']\n",
    "    summary_tables = {}\n",
    "\n",
    "    # Get the dataframes for the current patient ID\n",
    "    base_df = updated_base_df[ptid]\n",
    "    fine_tuned_df = updated_fine_tuned_df[ptid]\n",
    "    \n",
    "    for region in regions:\n",
    "        # Initialize empty DataFrame with specific dtypes to avoid warning\n",
    "        summary_df = pd.DataFrame({\n",
    "            'Model': pd.Series(dtype='object'),\n",
    "            'AP': pd.Series(dtype='int64'), \n",
    "            'BE': pd.Series(dtype='int64'), \n",
    "            'EP': pd.Series(dtype='int64'), \n",
    "            'Count': pd.Series(dtype='int64'),\n",
    "            'AP_pct': pd.Series(dtype='float64'), \n",
    "            'BE_pct': pd.Series(dtype='float64'), \n",
    "            'EP_pct': pd.Series(dtype='float64')\n",
    "        })\n",
    "        \n",
    "        # Process each model\n",
    "        for model, df in zip(['base model', 'fine-tuned models'], \n",
    "                            [base_df, fine_tuned_df]):\n",
    "            \n",
    "            # Filter for region if not overall\n",
    "            if region != 'overall':\n",
    "                region_df = df[df['glycemic_region'] == region]\n",
    "            else:\n",
    "                region_df = df\n",
    "                \n",
    "            # Calculate counts\n",
    "            ap_count = region_df['AP'].sum()\n",
    "            be_count = region_df['BE'].sum()\n",
    "            ep_count = region_df['EP'].sum()\n",
    "            total_count = len(region_df)\n",
    "            \n",
    "            # Create a new row as a dictionary and append it to the DataFrame\n",
    "            new_row = {\n",
    "                'Model': model, \n",
    "                'AP': ap_count, \n",
    "                'BE': be_count, \n",
    "                'EP': ep_count, \n",
    "                'Count': total_count,\n",
    "                'AP:EP': ap_count / ep_count if ep_count != 0 else np.nan,\n",
    "                'AP_pct': ap_count / total_count * 100, \n",
    "                'BE_pct': be_count / total_count * 100, \n",
    "                'EP_pct': ep_count / total_count * 100\n",
    "            }\n",
    "            summary_df = pd.concat([summary_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "        # Store in dictionary\n",
    "        summary_tables[region] = summary_df\n",
    "\n",
    "    # Create 1x2 grid figure with custom width ratios\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={'width_ratios': [1, 2]})\n",
    "\n",
    "    # PLOT 1: Overall AP percentage (left panel) - changed from EP to AP\n",
    "    sns.barplot(\n",
    "        x='Model', \n",
    "        y='AP_pct', \n",
    "        data=summary_tables['overall'], \n",
    "        ax=axs[0], \n",
    "        palette=palette,\n",
    "        hue='Model',\n",
    "        legend=False\n",
    "    )\n",
    "    axs[0].set_title(f'Overall Accuracy Percentage (Patient {ptid})', fontsize=14, fontweight='bold')\n",
    "    axs[0].set_ylabel('Accuracy Percentage (%)', fontsize=12)\n",
    "    axs[0].set_xlabel('')  # Remove x-axis label\n",
    "    axs[0].tick_params(axis='both', labelsize=9)\n",
    "    axs[0].set_ylim(0, 100)  # Adjusted y-axis range for percentage values\n",
    "\n",
    "    # Add data labels\n",
    "    for p in axs[0].patches:\n",
    "        axs[0].annotate(f\"{p.get_height():.1f}%\", \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "    # PLOT 2: AP percentage by Glycemic Region (right panel) - changed from EP to AP\n",
    "    # Create a new dataframe that combines the regional data for plotting\n",
    "    regional_data = pd.concat([\n",
    "        summary_tables['hypo'][['Model', 'AP_pct']].assign(Region='Hypo'),\n",
    "        summary_tables['eu'][['Model', 'AP_pct']].assign(Region='Eu'),\n",
    "        summary_tables['hyper'][['Model', 'AP_pct']].assign(Region='Hyper')\n",
    "    ])\n",
    "\n",
    "    sns.barplot(\n",
    "        x='Region', \n",
    "        y='AP_pct', \n",
    "        hue='Model',\n",
    "        data=regional_data, \n",
    "        ax=axs[1], \n",
    "        palette=palette\n",
    "    )\n",
    "    axs[1].set_title(f'Accuracy Percentage Across Glycemic Regions (Patient {ptid})', fontsize=14, fontweight='bold')\n",
    "    axs[1].set_ylabel('Accuracy Percentage (%)', fontsize=12)\n",
    "    axs[1].set_xlabel('Glycemic Region', fontsize=12)\n",
    "    axs[1].tick_params(axis='both', labelsize=10)\n",
    "    axs[1].set_ylim(0,100)  # Adjusted y-axis range for percentage values\n",
    "\n",
    "    # Add data labels to the second chart\n",
    "    for container in axs[1].containers:\n",
    "        axs[1].bar_label(container, fmt='%.1f%%', fontsize=11, fontweight='bold')\n",
    "\n",
    "    # Add legend to the right plot\n",
    "    axs[1].legend(title='Model', fontsize=9, title_fontsize=10)\n",
    "\n",
    "    # Remove top and right borders\n",
    "    sns.despine(ax=axs[0])\n",
    "    sns.despine(ax=axs[1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)  # Adjust to make room for the title\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute AP% differences for each glycemic region\n",
    "ptid_hypo_ap_diff = {}\n",
    "ptid_eu_ap_diff = {}\n",
    "ptid_hyper_ap_diff = {}\n",
    "\n",
    "for ptid in ptid_list:\n",
    "    # HYPO region\n",
    "    base_hypo_df = updated_base_df[ptid][updated_base_df[ptid]['glycemic_region'] == 'hypo']\n",
    "    fine_tuned_hypo_df = updated_fine_tuned_df[ptid][updated_fine_tuned_df[ptid]['glycemic_region'] == 'hypo']\n",
    "    \n",
    "    if len(base_hypo_df) > 0 and len(fine_tuned_hypo_df) > 0:\n",
    "        base_hypo_ap_pct = base_hypo_df['AP'].sum() / len(base_hypo_df) * 100\n",
    "        fine_tuned_hypo_ap_pct = fine_tuned_hypo_df['AP'].sum() / len(fine_tuned_hypo_df) * 100\n",
    "        ptid_hypo_ap_diff[ptid] = fine_tuned_hypo_ap_pct - base_hypo_ap_pct\n",
    "    \n",
    "    # EU region\n",
    "    base_eu_df = updated_base_df[ptid][updated_base_df[ptid]['glycemic_region'] == 'eu']\n",
    "    fine_tuned_eu_df = updated_fine_tuned_df[ptid][updated_fine_tuned_df[ptid]['glycemic_region'] == 'eu']\n",
    "    \n",
    "    if len(base_eu_df) > 0 and len(fine_tuned_eu_df) > 0:\n",
    "        base_eu_ap_pct = base_eu_df['AP'].sum() / len(base_eu_df) * 100\n",
    "        fine_tuned_eu_ap_pct = fine_tuned_eu_df['AP'].sum() / len(fine_tuned_eu_df) * 100\n",
    "        ptid_eu_ap_diff[ptid] = fine_tuned_eu_ap_pct - base_eu_ap_pct\n",
    "    \n",
    "    # HYPER region\n",
    "    base_hyper_df = updated_base_df[ptid][updated_base_df[ptid]['glycemic_region'] == 'hyper']\n",
    "    fine_tuned_hyper_df = updated_fine_tuned_df[ptid][updated_fine_tuned_df[ptid]['glycemic_region'] == 'hyper']\n",
    "    \n",
    "    if len(base_hyper_df) > 0 and len(fine_tuned_hyper_df) > 0:\n",
    "        base_hyper_ap_pct = base_hyper_df['AP'].sum() / len(base_hyper_df) * 100\n",
    "        fine_tuned_hyper_ap_pct = fine_tuned_hyper_df['AP'].sum() / len(fine_tuned_hyper_df) * 100\n",
    "        ptid_hyper_ap_diff[ptid] = fine_tuned_hyper_ap_pct - base_hyper_ap_pct\n",
    "\n",
    "\n",
    "\n",
    "# Create 3x1 plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 10))\n",
    "\n",
    "model1_color = (173 / 255, 29 / 255, 30 / 255)\n",
    "model2_color = (110 / 255, 180 / 255, 186 / 255)\n",
    "\n",
    "# ---- HYPOTHETIC REGION ----\n",
    "# Prepare significance dict\n",
    "hypo_significance_dict = {\n",
    "    row['Patient ID']: row['Significant']\n",
    "    for _, row in hypo_chi2_summary.iterrows()\n",
    "}\n",
    "hypo_df = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in sorted(ptid_hypo_ap_diff.keys())],\n",
    "    'AP Percentage Difference': [ptid_hypo_ap_diff[ptid] for ptid in sorted(ptid_hypo_ap_diff.keys())],\n",
    "    'Is_Significant': [hypo_significance_dict.get(ptid, False) for ptid in sorted(ptid_hypo_ap_diff.keys())]\n",
    "}).sort_values('AP Percentage Difference')\n",
    "\n",
    "hypo_colors = [model2_color if val > 0 else model1_color for val in hypo_df['AP Percentage Difference']]\n",
    "\n",
    "bars_hypo = axs[0].barh(hypo_df['Patient ID'], hypo_df['AP Percentage Difference'], color=hypo_colors)\n",
    "axs[0].set_title('Hypoglycemia', fontsize=16, fontweight='bold')\n",
    "axs[0].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "axs[0].set_xlim(-25, 25)\n",
    "axs[0].tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Annotate bars with value and asterisk\n",
    "for i, bar in enumerate(bars_hypo):\n",
    "    width = bar.get_width()\n",
    "    label_x_pos = width + 0.5 if width > 0 else width - 0.5\n",
    "    asterisk = '*' if hypo_df['Is_Significant'].iloc[i] else ''\n",
    "    axs[0].text(label_x_pos, bar.get_y() + bar.get_height()/2,\n",
    "                f'{abs(width):.1f}%{asterisk}', va='center',\n",
    "                ha='left' if width > 0 else 'right', fontsize=12)\n",
    "\n",
    "# ---- EUGLYCEMIC REGION ----\n",
    "eu_significance_dict = {\n",
    "    row['Patient ID']: row['Significant']\n",
    "    for _, row in eu_chi2_summary.iterrows()\n",
    "}\n",
    "\n",
    "eu_df = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in sorted(ptid_eu_ap_diff.keys())],\n",
    "    'AP Percentage Difference': [-ptid_eu_ap_diff[ptid] for ptid in sorted(ptid_eu_ap_diff.keys())],\n",
    "    'Is_Significant': [eu_significance_dict.get(ptid, False) for ptid in sorted(ptid_eu_ap_diff.keys())]\n",
    "}).set_index('Patient ID').reindex(hypo_df['Patient ID']).reset_index()\n",
    "\n",
    "eu_colors = [model2_color if val > 0 else model1_color for val in eu_df['AP Percentage Difference']]\n",
    "\n",
    "bars_eu = axs[1].barh(eu_df['Patient ID'], eu_df['AP Percentage Difference'], color=eu_colors)\n",
    "axs[1].set_title('Euglycemia', fontsize=16, fontweight='bold')\n",
    "axs[1].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "axs[1].set_xlim(-25, 25)\n",
    "axs[1].set_yticks([])\n",
    "axs[1].tick_params(axis='x', labelsize=14)\n",
    "\n",
    "for i, bar in enumerate(bars_eu):\n",
    "    width = bar.get_width()\n",
    "    label_x_pos = width + 0.5 if width > 0 else width - 0.5\n",
    "    asterisk = '*' if eu_df['Is_Significant'].iloc[i] else ''\n",
    "    axs[1].text(label_x_pos, bar.get_y() + bar.get_height()/2,\n",
    "                f'{abs(width):.1f}%{asterisk}', va='center',\n",
    "                ha='left' if width > 0 else 'right', fontsize=12)\n",
    "\n",
    "# ---- HYPERGLYCEMIC REGION ----\n",
    "hyper_significance_dict = {\n",
    "    row['Patient ID']: row['Significant']\n",
    "    for _, row in hyper_chi2_summary.iterrows()\n",
    "}\n",
    "\n",
    "hyper_df = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in sorted(ptid_hyper_ap_diff.keys())],\n",
    "    'AP Percentage Difference': [-ptid_hyper_ap_diff[ptid] for ptid in sorted(ptid_hyper_ap_diff.keys())],\n",
    "    'Is_Significant': [hyper_significance_dict.get(ptid, False) for ptid in sorted(ptid_hyper_ap_diff.keys())]\n",
    "}).set_index('Patient ID').reindex(hypo_df['Patient ID']).reset_index()\n",
    "\n",
    "hyper_colors = [model2_color if val > 0 else model1_color for val in hyper_df['AP Percentage Difference']]\n",
    "\n",
    "bars_hyper = axs[2].barh(hyper_df['Patient ID'], hyper_df['AP Percentage Difference'], color=hyper_colors)\n",
    "axs[2].set_title('Hyperglycemia', fontsize=16, fontweight='bold')\n",
    "axs[2].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "axs[2].set_xlim(-25, 25)\n",
    "axs[2].set_yticks([])\n",
    "\n",
    "for i, bar in enumerate(bars_hyper):\n",
    "    width = bar.get_width()\n",
    "    label_x_pos = width + 0.5 if width > 0 else width - 0.5\n",
    "    asterisk = '*' if hyper_df['Is_Significant'].iloc[i] else ''\n",
    "    axs[2].text(label_x_pos, bar.get_y() + bar.get_height()/2,\n",
    "                f'{abs(width):.1f}%{asterisk}', va='center',\n",
    "                ha='left' if width > 0 else 'right', fontsize=12)\n",
    "\n",
    "# Styling\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('AP Percentage Difference (%)', fontsize=12)\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.text(xlim[0]+0.5, ylim[0] - 1.25, 'Population\\n JPFormer better', \n",
    "            color=model1_color, fontsize=12, fontweight='bold', ha='left', va='top')\n",
    "    ax.text(xlim[1]-0.5, ylim[0] - 1.25, 'Personalised\\n JPFormer better', \n",
    "            color=model2_color, fontsize=12, fontweight='bold', ha='right', va='top')\n",
    "\n",
    "axs[1].spines['left'].set_visible(False)\n",
    "axs[2].spines['left'].set_visible(False)\n",
    "\n",
    "plt.suptitle('AP% Absolute Difference by Glycemic Region:\\nBase Model vs Fine-tuned Model', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute EP% differences for each glycemic region\n",
    "ptid_hypo_ep_diff = {}\n",
    "ptid_eu_ep_diff = {}\n",
    "ptid_hyper_ep_diff = {}\n",
    "\n",
    "for ptid in ptid_list:\n",
    "    # HYPO region\n",
    "    base_hypo_df = updated_base_df[ptid][updated_base_df[ptid]['glycemic_region'] == 'hypo']\n",
    "    fine_tuned_hypo_df = updated_fine_tuned_df[ptid][updated_fine_tuned_df[ptid]['glycemic_region'] == 'hypo']\n",
    "    \n",
    "    if len(base_hypo_df) > 0 and len(fine_tuned_hypo_df) > 0:\n",
    "        base_hypo_ep_pct = base_hypo_df['EP'].sum() / len(base_hypo_df) * 100\n",
    "        fine_tuned_hypo_ep_pct = fine_tuned_hypo_df['EP'].sum() / len(fine_tuned_hypo_df) * 100\n",
    "        ptid_hypo_ep_diff[ptid] = (fine_tuned_hypo_ep_pct - base_hypo_ep_pct)*-1\n",
    "    \n",
    "    # EU region\n",
    "    base_eu_df = updated_base_df[ptid][updated_base_df[ptid]['glycemic_region'] == 'eu']\n",
    "    fine_tuned_eu_df = updated_fine_tuned_df[ptid][updated_fine_tuned_df[ptid]['glycemic_region'] == 'eu']\n",
    "    \n",
    "    if len(base_eu_df) > 0 and len(fine_tuned_eu_df) > 0:\n",
    "        base_eu_ep_pct = base_eu_df['EP'].sum() / len(base_eu_df) * 100\n",
    "        fine_tuned_eu_ep_pct = fine_tuned_eu_df['EP'].sum() / len(fine_tuned_eu_df) * 100\n",
    "        ptid_eu_ep_diff[ptid] = fine_tuned_eu_ep_pct - base_eu_ep_pct\n",
    "    \n",
    "    # HYPER region\n",
    "    base_hyper_df = updated_base_df[ptid][updated_base_df[ptid]['glycemic_region'] == 'hyper']\n",
    "    fine_tuned_hyper_df = updated_fine_tuned_df[ptid][updated_fine_tuned_df[ptid]['glycemic_region'] == 'hyper']\n",
    "    \n",
    "    if len(base_hyper_df) > 0 and len(fine_tuned_hyper_df) > 0:\n",
    "        base_hyper_ep_pct = base_hyper_df['EP'].sum() / len(base_hyper_df) * 100\n",
    "        fine_tuned_hyper_ep_pct = fine_tuned_hyper_df['EP'].sum() / len(fine_tuned_hyper_df) * 100\n",
    "        ptid_hyper_ep_diff[ptid] = fine_tuned_hyper_ep_pct - base_hyper_ep_pct\n",
    "\n",
    "# Create 3x1 plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 10))\n",
    "\n",
    "model1_color = (173 / 255, 29 / 255, 30 / 255)\n",
    "model2_color = (110 / 255, 180 / 255, 186 / 255)\n",
    "\n",
    "# ---- HYPOTHETIC REGION ----\n",
    "hypo_significance_dict = {\n",
    "    row['Patient ID']: row['Significant']\n",
    "    for _, row in hypo_chi2_summary.iterrows()\n",
    "}\n",
    "hypo_df = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in sorted(ptid_hypo_ep_diff.keys())],\n",
    "    'EP Percentage Difference': [ptid_hypo_ep_diff[ptid] for ptid in sorted(ptid_hypo_ep_diff.keys())],\n",
    "    'Is_Significant': [hypo_significance_dict.get(ptid, False) for ptid in sorted(ptid_hypo_ep_diff.keys())]\n",
    "}).sort_values('EP Percentage Difference')\n",
    "\n",
    "hypo_colors = [model2_color if val > 0 else model1_color for val in hypo_df['EP Percentage Difference']]\n",
    "\n",
    "bars_hypo = axs[0].barh(hypo_df['Patient ID'], hypo_df['EP Percentage Difference'], color=hypo_colors)\n",
    "axs[0].set_title('Hypoglycemia', fontsize=16, fontweight='bold')\n",
    "axs[0].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "axs[0].set_xlim(-25, 25)\n",
    "axs[0].tick_params(axis='both', labelsize=14)\n",
    "\n",
    "for i, bar in enumerate(bars_hypo):\n",
    "    width = bar.get_width()\n",
    "    label_x_pos = width + 0.5 if width > 0 else width - 0.5\n",
    "    asterisk = '*' if hypo_df['Is_Significant'].iloc[i] else ''\n",
    "    axs[0].text(label_x_pos, bar.get_y() + bar.get_height()/2,\n",
    "                f'{abs(width):.1f}%{asterisk}', va='center',\n",
    "                ha='left' if width > 0 else 'right', fontsize=12)\n",
    "\n",
    "# ---- EUGLYCEMIC REGION ----\n",
    "eu_significance_dict = {\n",
    "    row['Patient ID']: row['Significant']\n",
    "    for _, row in eu_chi2_summary.iterrows()\n",
    "}\n",
    "\n",
    "eu_df = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in sorted(ptid_eu_ep_diff.keys())],\n",
    "    'EP Percentage Difference': [-ptid_eu_ep_diff[ptid] for ptid in sorted(ptid_eu_ep_diff.keys())],\n",
    "    'Is_Significant': [eu_significance_dict.get(ptid, False) for ptid in sorted(ptid_eu_ep_diff.keys())]\n",
    "}).set_index('Patient ID').reindex(hypo_df['Patient ID']).reset_index()\n",
    "\n",
    "eu_colors = [model2_color if val > 0 else model1_color for val in eu_df['EP Percentage Difference']]\n",
    "\n",
    "bars_eu = axs[1].barh(eu_df['Patient ID'], eu_df['EP Percentage Difference'], color=eu_colors)\n",
    "axs[1].set_title('Euglycemia', fontsize=16, fontweight='bold')\n",
    "axs[1].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "axs[1].set_xlim(-25, 25)\n",
    "axs[1].set_yticks([])\n",
    "axs[1].tick_params(axis='x', labelsize=14)\n",
    "\n",
    "for i, bar in enumerate(bars_eu):\n",
    "    width = bar.get_width()\n",
    "    label_x_pos = width + 0.5 if width > 0 else width - 0.5\n",
    "    asterisk = '*' if eu_df['Is_Significant'].iloc[i] else ''\n",
    "    axs[1].text(label_x_pos, bar.get_y() + bar.get_height()/2,\n",
    "                f'{abs(width):.1f}%{asterisk}', va='center',\n",
    "                ha='left' if width > 0 else 'right', fontsize=12)\n",
    "\n",
    "# ---- HYPERGLYCEMIC REGION ----\n",
    "hyper_significance_dict = {\n",
    "    row['Patient ID']: row['Significant']\n",
    "    for _, row in hyper_chi2_summary.iterrows()\n",
    "}\n",
    "\n",
    "hyper_df = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in sorted(ptid_hyper_ep_diff.keys())],\n",
    "    'EP Percentage Difference': [-ptid_hyper_ep_diff[ptid] for ptid in sorted(ptid_hyper_ep_diff.keys())],\n",
    "    'Is_Significant': [hyper_significance_dict.get(ptid, False) for ptid in sorted(ptid_hyper_ep_diff.keys())]\n",
    "}).set_index('Patient ID').reindex(hypo_df['Patient ID']).reset_index()\n",
    "\n",
    "hyper_colors = [model2_color if val > 0 else model1_color for val in hyper_df['EP Percentage Difference']]\n",
    "\n",
    "bars_hyper = axs[2].barh(hyper_df['Patient ID'], hyper_df['EP Percentage Difference'], color=hyper_colors)\n",
    "axs[2].set_title('Hyperglycemia', fontsize=16, fontweight='bold')\n",
    "axs[2].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "axs[2].set_xlim(-25, 25)\n",
    "axs[2].set_yticks([])\n",
    "\n",
    "for i, bar in enumerate(bars_hyper):\n",
    "    width = bar.get_width()\n",
    "    label_x_pos = width + 0.5 if width > 0 else width - 0.5\n",
    "    asterisk = '*' if hyper_df['Is_Significant'].iloc[i] else ''\n",
    "    axs[2].text(label_x_pos, bar.get_y() + bar.get_height()/2,\n",
    "                f'{abs(width):.1f}%{asterisk}', va='center',\n",
    "                ha='left' if width > 0 else 'right', fontsize=12)\n",
    "\n",
    "# Styling\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('EP Percentage Difference (%)', fontsize=12)\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.text(xlim[0]+0.5, ylim[0] - 1.25, 'Population\\n JPFormer better', \n",
    "            color=model1_color, fontsize=12, fontweight='bold', ha='left', va='top')\n",
    "    ax.text(xlim[1]-0.5, ylim[0] - 1.25, 'Personalised\\n JPFormer better', \n",
    "            color=model2_color, fontsize=12, fontweight='bold', ha='right', va='top')\n",
    "\n",
    "axs[1].spines['left'].set_visible(False)\n",
    "axs[2].spines['left'].set_visible(False)\n",
    "\n",
    "plt.suptitle('EP% Absolute Difference by Glycemic Region:\\nBase Model vs Fine-tuned Model', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# First, calculate the AP% and EP% differences\n",
    "ptid_overall_ap_diff = {}\n",
    "ptid_overall_ep_diff = {}\n",
    "\n",
    "for ptid in ptid_list:\n",
    "    # Get overall data\n",
    "    base_df = updated_base_df[ptid]\n",
    "    fine_tuned_df = updated_fine_tuned_df[ptid]\n",
    "    \n",
    "    base_total = len(base_df)\n",
    "    fine_tuned_total = len(fine_tuned_df)\n",
    "    \n",
    "    if base_total > 0 and fine_tuned_total > 0:\n",
    "        base_ap_pct = base_df['AP'].sum() / base_total * 100\n",
    "        fine_tuned_ap_pct = fine_tuned_df['AP'].sum() / fine_tuned_total * 100\n",
    "        ap_pct_diff = fine_tuned_ap_pct - base_ap_pct\n",
    "        ptid_overall_ap_diff[ptid] = ap_pct_diff\n",
    "        \n",
    "        base_ep_pct = base_df['EP'].sum() / base_total * 100\n",
    "        fine_tuned_ep_pct = fine_tuned_df['EP'].sum() / fine_tuned_total * 100\n",
    "        ep_pct_diff = fine_tuned_ep_pct - base_ep_pct\n",
    "        ptid_overall_ep_diff[ptid] = ep_pct_diff\n",
    "\n",
    "# Create more detailed DataFrames for tables\n",
    "comparison_df = pd.DataFrame(index=[f\"Patient {ptid}\" for ptid in ptid_list])\n",
    "\n",
    "# Add AP metrics\n",
    "comparison_df['AP% Base Model'] = [round(updated_base_df[ptid]['AP'].sum() / len(updated_base_df[ptid]) * 100, 2) if len(updated_base_df[ptid]) > 0 else 0 for ptid in ptid_list]\n",
    "comparison_df['AP% Fine-tuned'] = [round(updated_fine_tuned_df[ptid]['AP'].sum() / len(updated_fine_tuned_df[ptid]) * 100, 2) if len(updated_fine_tuned_df[ptid]) > 0 else 0 for ptid in ptid_list]\n",
    "comparison_df['AP% Difference'] = comparison_df['AP% Fine-tuned'] - comparison_df['AP% Base Model']\n",
    "\n",
    "# Add EP metrics\n",
    "comparison_df['EP% Base Model'] = [round(updated_base_df[ptid]['EP'].sum() / len(updated_base_df[ptid]) * 100, 2) if len(updated_base_df[ptid]) > 0 else 0 for ptid in ptid_list]\n",
    "comparison_df['EP% Fine-tuned'] = [round(updated_fine_tuned_df[ptid]['EP'].sum() / len(updated_fine_tuned_df[ptid]) * 100, 2) if len(updated_fine_tuned_df[ptid]) > 0 else 0 for ptid in ptid_list]\n",
    "comparison_df['EP% Difference'] = comparison_df['EP% Fine-tuned'] - comparison_df['EP% Base Model']\n",
    "\n",
    "# Sort by AP% Difference\n",
    "overall_comparison_df = comparison_df.sort_values('AP% Difference', ascending=False)\n",
    "\n",
    "# Style the dataframe for better visualization\n",
    "overall_styled_df = overall_comparison_df.style.background_gradient(subset=['AP% Difference', 'EP% Difference'], \n",
    "                                                  cmap='RdYlGn', \n",
    "                                                  vmin=-0.6, \n",
    "                                                  vmax=0.6)\n",
    "\n",
    "# Format to show percentage signs\n",
    "styled_df = styled_df.format(\"{:.2f}%\")\n",
    "\n",
    "# Add a title\n",
    "print(\"AP% and EP% Metrics: PopJPFormer vs PersJPFormer\")\n",
    "\n",
    "# Display the table\n",
    "display(overall_styled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a summary table showing the percentage change in hypoglycemia detection\n",
    "hypoglycemia_summary = pd.DataFrame({\n",
    "    'Patient ID': [f\"Patient {ptid}\" for ptid in sorted_ptids],\n",
    "    'Base AP%': [round(updated_base_df[ptid][updated_base_df[ptid]['glycemic_region'] == 'hypo']['AP'].mean() * 100, 1) \n",
    "                for ptid in sorted_ptids],\n",
    "    'Fine-tuned AP%': [round(updated_fine_tuned_df[ptid][updated_fine_tuned_df[ptid]['glycemic_region'] == 'hypo']['AP'].mean() * 100, 1) \n",
    "                      for ptid in sorted_ptids],\n",
    "    'AP% Change': [round(ptid_hypo_ap_diff[ptid], 1) for ptid in sorted_ptids],\n",
    "    'Base EP%': [round(updated_base_df[ptid][updated_base_df[ptid]['glycemic_region'] == 'hypo']['EP'].mean() * 100, 1) \n",
    "                for ptid in sorted_ptids],\n",
    "    'Fine-tuned EP%': [round(updated_fine_tuned_df[ptid][updated_fine_tuned_df[ptid]['glycemic_region'] == 'hypo']['EP'].mean() * 100, 1) \n",
    "                      for ptid in sorted_ptids],\n",
    "    'EP% Change': [round(-ptid_hypo_ep_diff[ptid], 1) for ptid in sorted_ptids]\n",
    "})\n",
    "\n",
    "# Style the DataFrame for better visualization\n",
    "hypo_styled_summary = hypoglycemia_summary\n",
    "\n",
    "# Display the table\n",
    "print(\"\\nHypoglycemia AP and EP% Performance by Patient\")\n",
    "display(hypo_styled_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypoglycaemia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_styled_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_styled_summary['EP% Improvement'] = hypo_styled_summary['EP% Change']*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_correlation(x, y):\n",
    "    pearson_corr, pearson_p = pearsonr(x, y)\n",
    "    spearman_corr, spearman_p = spearmanr(x, y)\n",
    "    return {\n",
    "        \"Pearson Coefficient\": pearson_corr,\n",
    "        \"Pearson p-value\": pearson_p,\n",
    "        \"Spearman Coefficient\": spearman_corr,\n",
    "        \"Spearman p-value\": spearman_p\n",
    "    }\n",
    "\n",
    "# Use the original DataFrame instead of the styled version\n",
    "base_ap_change_corr = compute_correlation(\n",
    "    hypoglycemia_summary['Base AP%'], \n",
    "    hypoglycemia_summary['AP% Change']\n",
    ")\n",
    "base_ep_change_corr = compute_correlation(\n",
    "    hypoglycemia_summary['Base EP%'], \n",
    "    hypoglycemia_summary['EP% Improvement']\n",
    ")\n",
    "\n",
    "# plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Scatter plot for Base AP% vs AP% Change\n",
    "axs[0].scatter(hypo_styled_summary['Base AP%'], hypo_styled_summary['AP% Change'], \n",
    "               color=model1_color, alpha=0.7)\n",
    "axs[0].set_title('AP% Improvement', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[0].set_xlabel('Base AP%', fontsize=14)\n",
    "axs[0].set_ylabel('AP% Change', fontsize=14)\n",
    "axs[0].tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Add regression line without confidence interval (ci=None)\n",
    "sns.regplot(x=hypo_styled_summary['Base AP%'], \n",
    "            y=hypo_styled_summary['AP% Change'], \n",
    "            ax=axs[0], \n",
    "            scatter=False, \n",
    "            color='black', \n",
    "            ci=None,\n",
    "            line_kws={'linestyle': '--', 'linewidth': 1})\n",
    "\n",
    "# Scatter plot for Base EP% vs EP% Change\n",
    "axs[1].scatter(hypo_styled_summary['Base EP%'], hypo_styled_summary['EP% Improvement'], \n",
    "               color=model1_color, alpha=0.7)\n",
    "axs[1].set_title('EP% Improvement', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[1].set_xlabel('Base EP%', fontsize=14)\n",
    "axs[1].set_ylabel('EP% Improvement', fontsize=14)\n",
    "axs[1].tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Add regression line without confidence interval (ci=None)\n",
    "sns.regplot(x=hypo_styled_summary['Base EP%'], \n",
    "            y=hypo_styled_summary['EP% Improvement'], \n",
    "            ax=axs[1], \n",
    "            scatter=False, \n",
    "            color='black', \n",
    "            ci=None,\n",
    "            line_kws={'linestyle': '--', 'linewidth': 1})\n",
    "\n",
    "# Add correlation coefficients to the plots\n",
    "axs[0].text(0.95, 0.95, f\"Pearson: {base_ap_change_corr['Spearman Coefficient']:.2f}\\np-value: {base_ap_change_corr['Spearman p-value']:.3f}\",\n",
    "            transform=axs[0].transAxes, \n",
    "            fontsize=12, \n",
    "            verticalalignment='top', \n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(facecolor='white', alpha=0.5))\n",
    "axs[1].text(0.05, 0.95, f\"Pearson: {base_ep_change_corr['Spearman Coefficient']:.2f}\\np-value: {base_ep_change_corr['Spearman p-value']:.3f}\",\n",
    "            transform=axs[1].transAxes, \n",
    "            fontsize=12, \n",
    "            verticalalignment='top', \n",
    "            bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "data = {\n",
    "    \"Patient ID\": [584, 575, 563, 559, 540, 596, 588, 570, 591, 567, 552, 544],\n",
    "    \"Total Slices\": [582, 3704, 2142, 1620, 5082, 876, 846, 1140, 1674, 2412, 1974, 1134]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_styled_summary['Total Traing Slices'] = df['Total Slices']\n",
    "hypo_styled_summary['Total Traing Slices'] = hypo_styled_summary['Total Traing Slices'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_correlation(x, y):\n",
    "    pearson_corr, pearson_p = pearsonr(x, y)\n",
    "    spearman_corr, spearman_p = spearmanr(x, y)\n",
    "    return {\n",
    "        \"Pearson Coefficient\": pearson_corr,\n",
    "        \"Pearson p-value\": pearson_p,\n",
    "        \"Spearman Coefficient\": spearman_corr,\n",
    "        \"Spearman p-value\": spearman_p\n",
    "    }\n",
    "\n",
    "# Use the original DataFrame instead of the styled version\n",
    "base_ap_change_corr = compute_correlation(\n",
    "    hypoglycemia_summary['Total Traing Slices'], \n",
    "    hypoglycemia_summary['AP% Change']\n",
    ")\n",
    "base_ep_change_corr = compute_correlation(\n",
    "    hypoglycemia_summary['Total Traing Slices'], \n",
    "    hypoglycemia_summary['EP% Improvement']\n",
    ")\n",
    "\n",
    "# plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Scatter plot for Base AP% vs AP% Change\n",
    "axs[0].scatter(hypo_styled_summary['Total Traing Slices'], hypo_styled_summary['AP% Change'], \n",
    "               color=model1_color, alpha=0.7)\n",
    "axs[0].set_title('AP% Improvement', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[0].set_xlabel('Total Traing Slices', fontsize=14)\n",
    "axs[0].set_ylabel('AP% Change', fontsize=14)\n",
    "axs[0].tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Add regression line without confidence interval (ci=None)\n",
    "sns.regplot(x=hypo_styled_summary['Total Traing Slices'], \n",
    "            y=hypo_styled_summary['AP% Change'], \n",
    "            ax=axs[0], \n",
    "            scatter=False, \n",
    "            color='black', \n",
    "            ci=None,\n",
    "            line_kws={'linestyle': '--', 'linewidth': 1})\n",
    "\n",
    "# Scatter plot for Base EP% vs EP% Change\n",
    "axs[1].scatter(hypo_styled_summary['Total Traing Slices'], hypo_styled_summary['EP% Improvement'], \n",
    "               color=model1_color, alpha=0.7)\n",
    "axs[1].set_title('EP% Improvement', fontsize=16, fontweight='bold', pad=20)\n",
    "axs[1].set_xlabel('Total Traing Slices', fontsize=14)\n",
    "axs[1].set_ylabel('EP% Improvement', fontsize=14)\n",
    "axs[1].tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Add regression line without confidence interval (ci=None)\n",
    "sns.regplot(x=hypo_styled_summary['Total Traing Slices'], \n",
    "            y=hypo_styled_summary['EP% Improvement'], \n",
    "            ax=axs[1], \n",
    "            scatter=False, \n",
    "            color='black', \n",
    "            ci=None,\n",
    "            line_kws={'linestyle': '--', 'linewidth': 1})\n",
    "\n",
    "# Add correlation coefficients to the plots\n",
    "axs[0].text(0.95, 0.95, f\"Pearson: {base_ap_change_corr['Spearman Coefficient']:.2f}\\np-value: {base_ap_change_corr['Spearman p-value']:.3f}\",\n",
    "            transform=axs[0].transAxes, \n",
    "            fontsize=12, \n",
    "            verticalalignment='top', \n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(facecolor='white', alpha=0.5))\n",
    "axs[1].text(0.05, 0.95, f\"Pearson: {base_ep_change_corr['Spearman Coefficient']:.2f}\\np-value: {base_ep_change_corr['Spearman p-value']:.3f}\",\n",
    "            transform=axs[1].transAxes, \n",
    "            fontsize=12, \n",
    "            verticalalignment='top', \n",
    "            bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
